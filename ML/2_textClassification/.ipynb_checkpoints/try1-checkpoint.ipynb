{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5638ee52",
   "metadata": {},
   "source": [
    "# CampusX NLP Playlist - sklearn [ML]\n",
    "- https://youtube.com/playlist?list=PLKnIA16_RmvZo7fp5kkIth6nRTeQQsjfX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145ecfcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "695eb0f6",
   "metadata": {},
   "source": [
    "# PyData London 2019 - PyTorch [DL]\n",
    "- https://youtu.be/4jROlXH9Nvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae08456e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "470fe998",
   "metadata": {},
   "source": [
    "# Ensemble model PyTorch Ensemble [DL - ensemble]\n",
    "- https://ensemble-pytorch.readthedocs.io/en/latest/introduction.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83243a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b4474cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MLP,self).__init__()\n",
    "        self.linear1 = nn.Linear(784,128)\n",
    "        self.linear2 = nn.Linear(128,128)\n",
    "        self.linear3 = nn.Linear(128,10)\n",
    "    def forward(self,data):\n",
    "        data = data.view(data.size(0), -1)\n",
    "        output = F.relu(self.linear1(data))\n",
    "        output = F.relu(self.linear2(output))\n",
    "        output = self.linear3(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ba95858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log will be saved in '/home/neelchoksi19bce0990/Documents/S/DLOM/ML/2_textClassification/logs'.\n",
      "Start logging into file /home/neelchoksi19bce0990/Documents/S/DLOM/ML/2_textClassification/logs/classification_mnist_mlp-2022_09_25_00_52.log...\n"
     ]
    }
   ],
   "source": [
    "from torchensemble.utils.logging import set_logger\n",
    "\n",
    "logger = set_logger('classification_mnist_mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "790427b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchensemble import VotingClassifier\n",
    "model = VotingClassifier(\n",
    "    estimator=MLP,\n",
    "    n_estimators=10,\n",
    "    cuda=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "105e9817",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "model.set_criterion(criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6963c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "train = datasets.MNIST('../Dataset', train=True, download=True, transform=transform)\n",
    "test = datasets.MNIST('../Dataset', train=False, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=128, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "937ba426",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_optimizer('Adam',\n",
    "                    lr=1e-3,\n",
    "                    weight_decay= 5e-4\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1e3b5a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 000 | Batch: 000 | Loss: 2.30669 | Correct: 11/128\n",
      "Estimator: 000 | Epoch: 000 | Batch: 100 | Loss: 0.36818 | Correct: 113/128\n",
      "Estimator: 000 | Epoch: 000 | Batch: 200 | Loss: 0.26253 | Correct: 119/128\n",
      "Estimator: 000 | Epoch: 000 | Batch: 300 | Loss: 0.15338 | Correct: 120/128\n",
      "Estimator: 000 | Epoch: 000 | Batch: 400 | Loss: 0.17372 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 000 | Batch: 000 | Loss: 2.31095 | Correct: 8/128\n",
      "Estimator: 001 | Epoch: 000 | Batch: 100 | Loss: 0.33060 | Correct: 112/128\n",
      "Estimator: 001 | Epoch: 000 | Batch: 200 | Loss: 0.19152 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 000 | Batch: 300 | Loss: 0.21431 | Correct: 119/128\n",
      "Estimator: 001 | Epoch: 000 | Batch: 400 | Loss: 0.18201 | Correct: 121/128\n",
      "Estimator: 002 | Epoch: 000 | Batch: 000 | Loss: 2.31526 | Correct: 12/128\n",
      "Estimator: 002 | Epoch: 000 | Batch: 100 | Loss: 0.23604 | Correct: 120/128\n",
      "Estimator: 002 | Epoch: 000 | Batch: 200 | Loss: 0.30289 | Correct: 114/128\n",
      "Estimator: 002 | Epoch: 000 | Batch: 300 | Loss: 0.17288 | Correct: 121/128\n",
      "Estimator: 002 | Epoch: 000 | Batch: 400 | Loss: 0.22215 | Correct: 120/128\n",
      "Estimator: 003 | Epoch: 000 | Batch: 000 | Loss: 2.30385 | Correct: 21/128\n",
      "Estimator: 003 | Epoch: 000 | Batch: 100 | Loss: 0.36814 | Correct: 113/128\n",
      "Estimator: 003 | Epoch: 000 | Batch: 200 | Loss: 0.20236 | Correct: 121/128\n",
      "Estimator: 003 | Epoch: 000 | Batch: 300 | Loss: 0.22256 | Correct: 118/128\n",
      "Estimator: 003 | Epoch: 000 | Batch: 400 | Loss: 0.13130 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 000 | Batch: 000 | Loss: 2.29668 | Correct: 7/128\n",
      "Estimator: 004 | Epoch: 000 | Batch: 100 | Loss: 0.39222 | Correct: 115/128\n",
      "Estimator: 004 | Epoch: 000 | Batch: 200 | Loss: 0.15818 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 000 | Batch: 300 | Loss: 0.17899 | Correct: 118/128\n",
      "Estimator: 004 | Epoch: 000 | Batch: 400 | Loss: 0.11560 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 000 | Batch: 000 | Loss: 2.29373 | Correct: 14/128\n",
      "Estimator: 005 | Epoch: 000 | Batch: 100 | Loss: 0.35204 | Correct: 111/128\n",
      "Estimator: 005 | Epoch: 000 | Batch: 200 | Loss: 0.11892 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 000 | Batch: 300 | Loss: 0.15565 | Correct: 122/128\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [42]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchensemble/voting.py:190\u001b[0m, in \u001b[0;36mVotingClassifier.fit\u001b[0;34m(self, train_loader, epochs, log_interval, test_loader, save_model, save_dir)\u001b[0m\n\u001b[1;32m    187\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParallelization on the training epoch: \u001b[39m\u001b[38;5;132;01m{:03d}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(msg\u001b[38;5;241m.\u001b[39mformat(epoch))\n\u001b[0;32m--> 190\u001b[0m rets \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_fit_per_epoch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcur_lr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_criterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mestimators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m estimators, optimizers \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m estimator, optimizer \u001b[38;5;129;01min\u001b[39;00m rets:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:1044\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1044\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1048\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:859\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 859\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:777\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    776\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 777\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchensemble/voting.py:47\u001b[0m, in \u001b[0;36m_parallel_fit_per_epoch\u001b[0;34m(train_loader, estimator, cur_lr, optimizer, criterion, idx, epoch, log_interval, device, is_classification)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cur_lr:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# Parallelization corrupts the binding between optimizer and scheduler\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     set_module\u001b[38;5;241m.\u001b[39mupdate_lr(optimizer, cur_lr)\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, elem \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     49\u001b[0m     data, target \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39msplit_data_target(elem, device)\n\u001b[1;32m     50\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    572\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/datasets/mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/transforms/transforms.py:270\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torchvision/transforms/functional.py:357\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    355\u001b[0m mean \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(mean, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    356\u001b[0m std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(std, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mstd\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m():\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd evaluated to zero after conversion to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, leading to division by zero.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mean\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_loader=train_loader,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c5e21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model.predict(test_loader)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "90538df4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 000 | Batch: 000 | Loss: 2.30089 | Correct: 8/128\n",
      "Estimator: 000 | Epoch: 000 | Batch: 100 | Loss: 0.42377 | Correct: 110/128\n",
      "Estimator: 000 | Epoch: 000 | Batch: 200 | Loss: 0.32272 | Correct: 117/128\n",
      "Estimator: 000 | Epoch: 000 | Batch: 300 | Loss: 0.20179 | Correct: 120/128\n",
      "Estimator: 000 | Epoch: 000 | Batch: 400 | Loss: 0.17933 | Correct: 120/128\n",
      "Estimator: 001 | Epoch: 000 | Batch: 000 | Loss: 2.29470 | Correct: 11/128\n",
      "Estimator: 001 | Epoch: 000 | Batch: 100 | Loss: 0.37939 | Correct: 114/128\n",
      "Estimator: 001 | Epoch: 000 | Batch: 200 | Loss: 0.26460 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 000 | Batch: 300 | Loss: 0.21057 | Correct: 119/128\n",
      "Estimator: 001 | Epoch: 000 | Batch: 400 | Loss: 0.12066 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 000 | Batch: 000 | Loss: 2.31498 | Correct: 11/128\n",
      "Estimator: 002 | Epoch: 000 | Batch: 100 | Loss: 0.33407 | Correct: 114/128\n",
      "Estimator: 002 | Epoch: 000 | Batch: 200 | Loss: 0.33838 | Correct: 117/128\n",
      "Estimator: 002 | Epoch: 000 | Batch: 300 | Loss: 0.17901 | Correct: 120/128\n",
      "Estimator: 002 | Epoch: 000 | Batch: 400 | Loss: 0.24077 | Correct: 121/128\n",
      "Estimator: 003 | Epoch: 000 | Batch: 000 | Loss: 2.30645 | Correct: 11/128\n",
      "Estimator: 003 | Epoch: 000 | Batch: 100 | Loss: 0.29913 | Correct: 120/128\n",
      "Estimator: 003 | Epoch: 000 | Batch: 200 | Loss: 0.35441 | Correct: 113/128\n",
      "Estimator: 003 | Epoch: 000 | Batch: 300 | Loss: 0.10601 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 000 | Batch: 400 | Loss: 0.20905 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 000 | Batch: 000 | Loss: 2.30551 | Correct: 19/128\n",
      "Estimator: 004 | Epoch: 000 | Batch: 100 | Loss: 0.47441 | Correct: 109/128\n",
      "Estimator: 004 | Epoch: 000 | Batch: 200 | Loss: 0.23412 | Correct: 118/128\n",
      "Estimator: 004 | Epoch: 000 | Batch: 300 | Loss: 0.14217 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 000 | Batch: 400 | Loss: 0.07202 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 000 | Batch: 000 | Loss: 2.30501 | Correct: 15/128\n",
      "Estimator: 005 | Epoch: 000 | Batch: 100 | Loss: 0.57084 | Correct: 110/128\n",
      "Estimator: 005 | Epoch: 000 | Batch: 200 | Loss: 0.20745 | Correct: 120/128\n",
      "Estimator: 005 | Epoch: 000 | Batch: 300 | Loss: 0.17948 | Correct: 121/128\n",
      "Estimator: 005 | Epoch: 000 | Batch: 400 | Loss: 0.16788 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 000 | Batch: 000 | Loss: 2.29168 | Correct: 16/128\n",
      "Estimator: 006 | Epoch: 000 | Batch: 100 | Loss: 0.25642 | Correct: 119/128\n",
      "Estimator: 006 | Epoch: 000 | Batch: 200 | Loss: 0.26531 | Correct: 119/128\n",
      "Estimator: 006 | Epoch: 000 | Batch: 300 | Loss: 0.15935 | Correct: 121/128\n",
      "Estimator: 006 | Epoch: 000 | Batch: 400 | Loss: 0.08695 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 000 | Batch: 000 | Loss: 2.29220 | Correct: 19/128\n",
      "Estimator: 007 | Epoch: 000 | Batch: 100 | Loss: 0.25200 | Correct: 115/128\n",
      "Estimator: 007 | Epoch: 000 | Batch: 200 | Loss: 0.17758 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 000 | Batch: 300 | Loss: 0.13045 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 000 | Batch: 400 | Loss: 0.23010 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 000 | Batch: 000 | Loss: 2.32005 | Correct: 2/128\n",
      "Estimator: 008 | Epoch: 000 | Batch: 100 | Loss: 0.22043 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 000 | Batch: 200 | Loss: 0.18147 | Correct: 119/128\n",
      "Estimator: 008 | Epoch: 000 | Batch: 300 | Loss: 0.22371 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 000 | Batch: 400 | Loss: 0.16493 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 000 | Batch: 000 | Loss: 2.30861 | Correct: 12/128\n",
      "Estimator: 009 | Epoch: 000 | Batch: 100 | Loss: 0.37257 | Correct: 117/128\n",
      "Estimator: 009 | Epoch: 000 | Batch: 200 | Loss: 0.23187 | Correct: 120/128\n",
      "Estimator: 009 | Epoch: 000 | Batch: 300 | Loss: 0.27157 | Correct: 116/128\n",
      "Estimator: 009 | Epoch: 000 | Batch: 400 | Loss: 0.24696 | Correct: 119/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 00:55:11,784 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 00:55:11,784 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 00:55:11,800 - INFO: Epoch: 000 | Validation Acc: 96.240 % | Historical Best: 96.240 %\n",
      "2022-09-25 00:55:11,800 - INFO: Epoch: 000 | Validation Acc: 96.240 % | Historical Best: 96.240 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 001 | Batch: 000 | Loss: 0.18590 | Correct: 120/128\n",
      "Estimator: 000 | Epoch: 001 | Batch: 100 | Loss: 0.12624 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 001 | Batch: 200 | Loss: 0.08047 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 001 | Batch: 300 | Loss: 0.12152 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 001 | Batch: 400 | Loss: 0.05414 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 001 | Batch: 000 | Loss: 0.20308 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 001 | Batch: 100 | Loss: 0.23666 | Correct: 119/128\n",
      "Estimator: 001 | Epoch: 001 | Batch: 200 | Loss: 0.18645 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 001 | Batch: 300 | Loss: 0.11854 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 001 | Batch: 400 | Loss: 0.12101 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 001 | Batch: 000 | Loss: 0.09717 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 001 | Batch: 100 | Loss: 0.13230 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 001 | Batch: 200 | Loss: 0.08576 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 001 | Batch: 300 | Loss: 0.07481 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 001 | Batch: 400 | Loss: 0.15330 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 001 | Batch: 000 | Loss: 0.10842 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 001 | Batch: 100 | Loss: 0.04530 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 001 | Batch: 200 | Loss: 0.14240 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 001 | Batch: 300 | Loss: 0.18587 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 001 | Batch: 400 | Loss: 0.08202 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 001 | Batch: 000 | Loss: 0.20660 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 001 | Batch: 100 | Loss: 0.08800 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 001 | Batch: 200 | Loss: 0.12771 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 001 | Batch: 300 | Loss: 0.20758 | Correct: 121/128\n",
      "Estimator: 004 | Epoch: 001 | Batch: 400 | Loss: 0.10643 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 001 | Batch: 000 | Loss: 0.13903 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 001 | Batch: 100 | Loss: 0.20626 | Correct: 120/128\n",
      "Estimator: 005 | Epoch: 001 | Batch: 200 | Loss: 0.06866 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 001 | Batch: 300 | Loss: 0.19381 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 001 | Batch: 400 | Loss: 0.08523 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 001 | Batch: 000 | Loss: 0.18764 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 001 | Batch: 100 | Loss: 0.18631 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 001 | Batch: 200 | Loss: 0.05659 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 001 | Batch: 300 | Loss: 0.07427 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 001 | Batch: 400 | Loss: 0.18881 | Correct: 118/128\n",
      "Estimator: 007 | Epoch: 001 | Batch: 000 | Loss: 0.17347 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 001 | Batch: 100 | Loss: 0.18062 | Correct: 119/128\n",
      "Estimator: 007 | Epoch: 001 | Batch: 200 | Loss: 0.07076 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 001 | Batch: 300 | Loss: 0.07790 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 001 | Batch: 400 | Loss: 0.16225 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 001 | Batch: 000 | Loss: 0.10838 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 001 | Batch: 100 | Loss: 0.07476 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 001 | Batch: 200 | Loss: 0.07826 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 001 | Batch: 300 | Loss: 0.11032 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 001 | Batch: 400 | Loss: 0.13741 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 001 | Batch: 000 | Loss: 0.10017 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 001 | Batch: 100 | Loss: 0.13862 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 001 | Batch: 200 | Loss: 0.08802 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 001 | Batch: 300 | Loss: 0.08932 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 001 | Batch: 400 | Loss: 0.14510 | Correct: 121/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 00:56:49,167 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 00:56:49,167 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 00:56:49,181 - INFO: Epoch: 001 | Validation Acc: 97.500 % | Historical Best: 97.500 %\n",
      "2022-09-25 00:56:49,181 - INFO: Epoch: 001 | Validation Acc: 97.500 % | Historical Best: 97.500 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 002 | Batch: 000 | Loss: 0.05159 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 002 | Batch: 100 | Loss: 0.07640 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 002 | Batch: 200 | Loss: 0.07031 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 002 | Batch: 300 | Loss: 0.11681 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 002 | Batch: 400 | Loss: 0.04835 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 002 | Batch: 000 | Loss: 0.05958 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 002 | Batch: 100 | Loss: 0.04603 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 002 | Batch: 200 | Loss: 0.10172 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 002 | Batch: 300 | Loss: 0.12576 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 002 | Batch: 400 | Loss: 0.16014 | Correct: 116/128\n",
      "Estimator: 002 | Epoch: 002 | Batch: 000 | Loss: 0.08184 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 002 | Batch: 100 | Loss: 0.13006 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 002 | Batch: 200 | Loss: 0.09603 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 002 | Batch: 300 | Loss: 0.13205 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 002 | Batch: 400 | Loss: 0.10821 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 002 | Batch: 000 | Loss: 0.19839 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 002 | Batch: 100 | Loss: 0.06374 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 002 | Batch: 200 | Loss: 0.07049 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 002 | Batch: 300 | Loss: 0.09719 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 002 | Batch: 400 | Loss: 0.05827 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 002 | Batch: 000 | Loss: 0.06442 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 002 | Batch: 100 | Loss: 0.08053 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 002 | Batch: 200 | Loss: 0.09211 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 002 | Batch: 300 | Loss: 0.12752 | Correct: 120/128\n",
      "Estimator: 004 | Epoch: 002 | Batch: 400 | Loss: 0.19826 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 002 | Batch: 000 | Loss: 0.10214 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 002 | Batch: 100 | Loss: 0.09871 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 002 | Batch: 200 | Loss: 0.05329 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 002 | Batch: 300 | Loss: 0.11685 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 002 | Batch: 400 | Loss: 0.07242 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 002 | Batch: 000 | Loss: 0.17334 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 002 | Batch: 100 | Loss: 0.04811 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 002 | Batch: 200 | Loss: 0.06207 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 002 | Batch: 300 | Loss: 0.15577 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 002 | Batch: 400 | Loss: 0.06750 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 002 | Batch: 000 | Loss: 0.09620 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 002 | Batch: 100 | Loss: 0.14067 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 002 | Batch: 200 | Loss: 0.08656 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 002 | Batch: 300 | Loss: 0.09313 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 002 | Batch: 400 | Loss: 0.06078 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 002 | Batch: 000 | Loss: 0.09380 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 002 | Batch: 100 | Loss: 0.15748 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 002 | Batch: 200 | Loss: 0.10094 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 002 | Batch: 300 | Loss: 0.03868 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 002 | Batch: 400 | Loss: 0.05502 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 002 | Batch: 000 | Loss: 0.04817 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 002 | Batch: 100 | Loss: 0.13856 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 002 | Batch: 200 | Loss: 0.07522 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 002 | Batch: 300 | Loss: 0.08794 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 002 | Batch: 400 | Loss: 0.05803 | Correct: 126/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 00:58:29,005 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 00:58:29,005 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 00:58:29,019 - INFO: Epoch: 002 | Validation Acc: 98.000 % | Historical Best: 98.000 %\n",
      "2022-09-25 00:58:29,019 - INFO: Epoch: 002 | Validation Acc: 98.000 % | Historical Best: 98.000 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 003 | Batch: 000 | Loss: 0.03459 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 003 | Batch: 100 | Loss: 0.05124 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 003 | Batch: 200 | Loss: 0.09135 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 003 | Batch: 300 | Loss: 0.09873 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 003 | Batch: 400 | Loss: 0.02665 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 003 | Batch: 000 | Loss: 0.08576 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 003 | Batch: 100 | Loss: 0.05183 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 003 | Batch: 200 | Loss: 0.07512 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 003 | Batch: 300 | Loss: 0.08578 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 003 | Batch: 400 | Loss: 0.06208 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 003 | Batch: 000 | Loss: 0.06655 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 003 | Batch: 100 | Loss: 0.07425 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 003 | Batch: 200 | Loss: 0.07186 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 003 | Batch: 300 | Loss: 0.02678 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 003 | Batch: 400 | Loss: 0.08835 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 003 | Batch: 000 | Loss: 0.01827 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 003 | Batch: 100 | Loss: 0.06255 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 003 | Batch: 200 | Loss: 0.05712 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 003 | Batch: 300 | Loss: 0.05084 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 003 | Batch: 400 | Loss: 0.12690 | Correct: 120/128\n",
      "Estimator: 004 | Epoch: 003 | Batch: 000 | Loss: 0.15515 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 003 | Batch: 100 | Loss: 0.13904 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 003 | Batch: 200 | Loss: 0.04937 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 003 | Batch: 300 | Loss: 0.13025 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 003 | Batch: 400 | Loss: 0.12517 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 003 | Batch: 000 | Loss: 0.04563 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 003 | Batch: 100 | Loss: 0.07181 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 003 | Batch: 200 | Loss: 0.08372 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 003 | Batch: 300 | Loss: 0.03661 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 003 | Batch: 400 | Loss: 0.11371 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 003 | Batch: 000 | Loss: 0.07858 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 003 | Batch: 100 | Loss: 0.03940 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 003 | Batch: 200 | Loss: 0.06896 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 003 | Batch: 300 | Loss: 0.14820 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 003 | Batch: 400 | Loss: 0.05411 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 003 | Batch: 000 | Loss: 0.04686 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 003 | Batch: 100 | Loss: 0.02637 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 003 | Batch: 200 | Loss: 0.09410 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 003 | Batch: 300 | Loss: 0.10298 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 003 | Batch: 400 | Loss: 0.04840 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 003 | Batch: 000 | Loss: 0.04859 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 003 | Batch: 100 | Loss: 0.08968 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 003 | Batch: 200 | Loss: 0.03667 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 003 | Batch: 300 | Loss: 0.02130 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 003 | Batch: 400 | Loss: 0.11036 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 003 | Batch: 000 | Loss: 0.09447 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 003 | Batch: 100 | Loss: 0.09971 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 003 | Batch: 200 | Loss: 0.04983 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 003 | Batch: 300 | Loss: 0.09367 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 003 | Batch: 400 | Loss: 0.08332 | Correct: 124/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:00:08,569 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:00:08,569 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:00:08,582 - INFO: Epoch: 003 | Validation Acc: 98.070 % | Historical Best: 98.070 %\n",
      "2022-09-25 01:00:08,582 - INFO: Epoch: 003 | Validation Acc: 98.070 % | Historical Best: 98.070 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 004 | Batch: 000 | Loss: 0.08555 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 004 | Batch: 100 | Loss: 0.08102 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 004 | Batch: 200 | Loss: 0.03571 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 004 | Batch: 300 | Loss: 0.07540 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 004 | Batch: 400 | Loss: 0.03313 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 004 | Batch: 000 | Loss: 0.04527 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 004 | Batch: 100 | Loss: 0.03124 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 004 | Batch: 200 | Loss: 0.05348 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 004 | Batch: 300 | Loss: 0.06952 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 004 | Batch: 400 | Loss: 0.06097 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 004 | Batch: 000 | Loss: 0.07529 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 004 | Batch: 100 | Loss: 0.03398 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 004 | Batch: 200 | Loss: 0.12308 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 004 | Batch: 300 | Loss: 0.01825 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 004 | Batch: 400 | Loss: 0.02549 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 004 | Batch: 000 | Loss: 0.08739 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 004 | Batch: 100 | Loss: 0.09042 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 004 | Batch: 200 | Loss: 0.05049 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 004 | Batch: 300 | Loss: 0.01016 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 004 | Batch: 400 | Loss: 0.10383 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 004 | Batch: 000 | Loss: 0.05356 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 004 | Batch: 100 | Loss: 0.07530 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 004 | Batch: 200 | Loss: 0.11113 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 004 | Batch: 300 | Loss: 0.03310 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 004 | Batch: 400 | Loss: 0.05387 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 004 | Batch: 000 | Loss: 0.01975 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 004 | Batch: 100 | Loss: 0.05342 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 004 | Batch: 200 | Loss: 0.02060 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 004 | Batch: 300 | Loss: 0.08654 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 004 | Batch: 400 | Loss: 0.02834 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 004 | Batch: 000 | Loss: 0.02886 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 004 | Batch: 100 | Loss: 0.05706 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 004 | Batch: 200 | Loss: 0.02036 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 004 | Batch: 300 | Loss: 0.08938 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 004 | Batch: 400 | Loss: 0.06669 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 004 | Batch: 000 | Loss: 0.06107 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 004 | Batch: 100 | Loss: 0.04190 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 004 | Batch: 200 | Loss: 0.06901 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 004 | Batch: 300 | Loss: 0.05164 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 004 | Batch: 400 | Loss: 0.10543 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 004 | Batch: 000 | Loss: 0.02725 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 004 | Batch: 100 | Loss: 0.04773 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 004 | Batch: 200 | Loss: 0.03943 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 004 | Batch: 300 | Loss: 0.06764 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 004 | Batch: 400 | Loss: 0.07015 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 004 | Batch: 000 | Loss: 0.03293 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 004 | Batch: 100 | Loss: 0.13949 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 004 | Batch: 200 | Loss: 0.08506 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 004 | Batch: 300 | Loss: 0.08396 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 004 | Batch: 400 | Loss: 0.08963 | Correct: 124/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:01:46,046 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:01:46,046 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:01:46,059 - INFO: Epoch: 004 | Validation Acc: 98.300 % | Historical Best: 98.300 %\n",
      "2022-09-25 01:01:46,059 - INFO: Epoch: 004 | Validation Acc: 98.300 % | Historical Best: 98.300 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 005 | Batch: 000 | Loss: 0.03340 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 005 | Batch: 100 | Loss: 0.05345 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 005 | Batch: 200 | Loss: 0.04933 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 005 | Batch: 300 | Loss: 0.06769 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 005 | Batch: 400 | Loss: 0.05843 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 005 | Batch: 000 | Loss: 0.08582 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 005 | Batch: 100 | Loss: 0.00802 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 005 | Batch: 200 | Loss: 0.08109 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 005 | Batch: 300 | Loss: 0.04996 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 005 | Batch: 400 | Loss: 0.17847 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 005 | Batch: 000 | Loss: 0.03842 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 005 | Batch: 100 | Loss: 0.08809 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 005 | Batch: 200 | Loss: 0.09290 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 005 | Batch: 300 | Loss: 0.04047 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 005 | Batch: 400 | Loss: 0.03108 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 005 | Batch: 000 | Loss: 0.05333 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 005 | Batch: 100 | Loss: 0.07381 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 005 | Batch: 200 | Loss: 0.02339 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 005 | Batch: 300 | Loss: 0.03555 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 005 | Batch: 400 | Loss: 0.04263 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 005 | Batch: 000 | Loss: 0.06155 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 005 | Batch: 100 | Loss: 0.02409 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 005 | Batch: 200 | Loss: 0.03781 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 005 | Batch: 300 | Loss: 0.06498 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 005 | Batch: 400 | Loss: 0.12471 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 005 | Batch: 000 | Loss: 0.10327 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 005 | Batch: 100 | Loss: 0.07877 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 005 | Batch: 200 | Loss: 0.08406 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 005 | Batch: 300 | Loss: 0.04709 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 005 | Batch: 400 | Loss: 0.08393 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 005 | Batch: 000 | Loss: 0.03985 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 005 | Batch: 100 | Loss: 0.07491 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 005 | Batch: 200 | Loss: 0.01530 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 005 | Batch: 300 | Loss: 0.04057 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 005 | Batch: 400 | Loss: 0.01280 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 005 | Batch: 000 | Loss: 0.05312 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 005 | Batch: 100 | Loss: 0.08988 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 005 | Batch: 200 | Loss: 0.03672 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 005 | Batch: 300 | Loss: 0.07276 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 005 | Batch: 400 | Loss: 0.02611 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 005 | Batch: 000 | Loss: 0.07965 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 005 | Batch: 100 | Loss: 0.02471 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 005 | Batch: 200 | Loss: 0.02098 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 005 | Batch: 300 | Loss: 0.03686 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 005 | Batch: 400 | Loss: 0.08131 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 005 | Batch: 000 | Loss: 0.02190 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 005 | Batch: 100 | Loss: 0.04749 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 005 | Batch: 200 | Loss: 0.02844 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 005 | Batch: 300 | Loss: 0.03788 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 005 | Batch: 400 | Loss: 0.04520 | Correct: 125/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:03:24,365 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:03:24,365 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:03:24,482 - INFO: Epoch: 005 | Validation Acc: 98.390 % | Historical Best: 98.390 %\n",
      "2022-09-25 01:03:24,482 - INFO: Epoch: 005 | Validation Acc: 98.390 % | Historical Best: 98.390 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 006 | Batch: 000 | Loss: 0.02604 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 006 | Batch: 100 | Loss: 0.01811 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 006 | Batch: 200 | Loss: 0.02411 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 006 | Batch: 300 | Loss: 0.01503 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 006 | Batch: 400 | Loss: 0.08641 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 006 | Batch: 000 | Loss: 0.08075 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 006 | Batch: 100 | Loss: 0.13745 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 006 | Batch: 200 | Loss: 0.02314 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 006 | Batch: 300 | Loss: 0.02924 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 006 | Batch: 400 | Loss: 0.06182 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 006 | Batch: 000 | Loss: 0.02836 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 006 | Batch: 100 | Loss: 0.02875 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 006 | Batch: 200 | Loss: 0.02909 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 006 | Batch: 300 | Loss: 0.03557 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 006 | Batch: 400 | Loss: 0.07930 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 006 | Batch: 000 | Loss: 0.08192 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 006 | Batch: 100 | Loss: 0.02356 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 006 | Batch: 200 | Loss: 0.05652 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 006 | Batch: 300 | Loss: 0.02884 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 006 | Batch: 400 | Loss: 0.03729 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 006 | Batch: 000 | Loss: 0.03514 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 006 | Batch: 100 | Loss: 0.02998 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 006 | Batch: 200 | Loss: 0.01510 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 006 | Batch: 300 | Loss: 0.09300 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 006 | Batch: 400 | Loss: 0.02564 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 006 | Batch: 000 | Loss: 0.03740 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 006 | Batch: 100 | Loss: 0.07061 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 006 | Batch: 200 | Loss: 0.04530 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 006 | Batch: 300 | Loss: 0.06052 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 006 | Batch: 400 | Loss: 0.09787 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 006 | Batch: 000 | Loss: 0.04222 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 006 | Batch: 100 | Loss: 0.04859 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 006 | Batch: 200 | Loss: 0.01984 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 006 | Batch: 300 | Loss: 0.05355 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 006 | Batch: 400 | Loss: 0.02860 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 006 | Batch: 000 | Loss: 0.06562 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 006 | Batch: 100 | Loss: 0.04607 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 006 | Batch: 200 | Loss: 0.03730 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 006 | Batch: 300 | Loss: 0.07851 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 006 | Batch: 400 | Loss: 0.11217 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 006 | Batch: 000 | Loss: 0.04713 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 006 | Batch: 100 | Loss: 0.00736 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 006 | Batch: 200 | Loss: 0.02905 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 006 | Batch: 300 | Loss: 0.07359 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 006 | Batch: 400 | Loss: 0.04445 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 006 | Batch: 000 | Loss: 0.02360 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 006 | Batch: 100 | Loss: 0.01184 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 006 | Batch: 200 | Loss: 0.03843 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 006 | Batch: 300 | Loss: 0.04391 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 006 | Batch: 400 | Loss: 0.08755 | Correct: 125/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:05:02,969 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:05:02,969 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:05:03,086 - INFO: Epoch: 006 | Validation Acc: 98.460 % | Historical Best: 98.460 %\n",
      "2022-09-25 01:05:03,086 - INFO: Epoch: 006 | Validation Acc: 98.460 % | Historical Best: 98.460 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 007 | Batch: 000 | Loss: 0.06323 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 007 | Batch: 100 | Loss: 0.08149 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 007 | Batch: 200 | Loss: 0.03989 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 007 | Batch: 300 | Loss: 0.02748 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 007 | Batch: 400 | Loss: 0.04834 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 007 | Batch: 000 | Loss: 0.02508 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 007 | Batch: 100 | Loss: 0.03225 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 007 | Batch: 200 | Loss: 0.10927 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 007 | Batch: 300 | Loss: 0.03415 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 007 | Batch: 400 | Loss: 0.24153 | Correct: 120/128\n",
      "Estimator: 002 | Epoch: 007 | Batch: 000 | Loss: 0.01466 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 007 | Batch: 100 | Loss: 0.05658 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 007 | Batch: 200 | Loss: 0.08424 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 007 | Batch: 300 | Loss: 0.01910 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 007 | Batch: 400 | Loss: 0.05848 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 007 | Batch: 000 | Loss: 0.01353 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 007 | Batch: 100 | Loss: 0.02263 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 007 | Batch: 200 | Loss: 0.03145 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 007 | Batch: 300 | Loss: 0.03763 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 007 | Batch: 400 | Loss: 0.02668 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 007 | Batch: 000 | Loss: 0.00877 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 007 | Batch: 100 | Loss: 0.01447 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 007 | Batch: 200 | Loss: 0.02917 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 007 | Batch: 300 | Loss: 0.11081 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 007 | Batch: 400 | Loss: 0.05157 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 007 | Batch: 000 | Loss: 0.02926 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 007 | Batch: 100 | Loss: 0.03546 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 007 | Batch: 200 | Loss: 0.04714 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 007 | Batch: 300 | Loss: 0.03969 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 007 | Batch: 400 | Loss: 0.03866 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 007 | Batch: 000 | Loss: 0.02889 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 007 | Batch: 100 | Loss: 0.02459 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 007 | Batch: 200 | Loss: 0.04416 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 007 | Batch: 300 | Loss: 0.01765 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 007 | Batch: 400 | Loss: 0.05813 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 007 | Batch: 000 | Loss: 0.04161 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 007 | Batch: 100 | Loss: 0.01907 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 007 | Batch: 200 | Loss: 0.02293 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 007 | Batch: 300 | Loss: 0.02889 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 007 | Batch: 400 | Loss: 0.01974 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 007 | Batch: 000 | Loss: 0.01942 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 007 | Batch: 100 | Loss: 0.06609 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 007 | Batch: 200 | Loss: 0.01199 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 007 | Batch: 300 | Loss: 0.01512 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 007 | Batch: 400 | Loss: 0.06663 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 007 | Batch: 000 | Loss: 0.01542 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 007 | Batch: 100 | Loss: 0.01903 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 007 | Batch: 200 | Loss: 0.01519 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 007 | Batch: 300 | Loss: 0.04318 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 007 | Batch: 400 | Loss: 0.01710 | Correct: 127/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:06:42,092 - INFO: Epoch: 007 | Validation Acc: 98.360 % | Historical Best: 98.460 %\n",
      "2022-09-25 01:06:42,092 - INFO: Epoch: 007 | Validation Acc: 98.360 % | Historical Best: 98.460 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 008 | Batch: 000 | Loss: 0.02503 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 008 | Batch: 100 | Loss: 0.03517 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 008 | Batch: 200 | Loss: 0.01679 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 008 | Batch: 300 | Loss: 0.05778 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 008 | Batch: 400 | Loss: 0.07912 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 008 | Batch: 000 | Loss: 0.03321 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 008 | Batch: 100 | Loss: 0.00284 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 008 | Batch: 200 | Loss: 0.03351 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 008 | Batch: 300 | Loss: 0.02802 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 008 | Batch: 400 | Loss: 0.04559 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 008 | Batch: 000 | Loss: 0.02348 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 008 | Batch: 100 | Loss: 0.02487 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 008 | Batch: 200 | Loss: 0.12011 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 008 | Batch: 300 | Loss: 0.06486 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 008 | Batch: 400 | Loss: 0.02718 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 008 | Batch: 000 | Loss: 0.01757 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 008 | Batch: 100 | Loss: 0.01119 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 008 | Batch: 200 | Loss: 0.07739 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 008 | Batch: 300 | Loss: 0.03708 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 008 | Batch: 400 | Loss: 0.02448 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 008 | Batch: 000 | Loss: 0.01790 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 008 | Batch: 100 | Loss: 0.02296 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 008 | Batch: 200 | Loss: 0.06036 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 008 | Batch: 300 | Loss: 0.02026 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 008 | Batch: 400 | Loss: 0.05314 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 008 | Batch: 000 | Loss: 0.01335 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 008 | Batch: 100 | Loss: 0.01403 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 008 | Batch: 200 | Loss: 0.01836 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 008 | Batch: 300 | Loss: 0.01187 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 008 | Batch: 400 | Loss: 0.05310 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 008 | Batch: 000 | Loss: 0.02088 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 008 | Batch: 100 | Loss: 0.01306 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 008 | Batch: 200 | Loss: 0.04639 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 008 | Batch: 300 | Loss: 0.02922 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 008 | Batch: 400 | Loss: 0.05400 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 008 | Batch: 000 | Loss: 0.05630 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 008 | Batch: 100 | Loss: 0.01410 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 008 | Batch: 200 | Loss: 0.06906 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 008 | Batch: 300 | Loss: 0.02808 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 008 | Batch: 400 | Loss: 0.04198 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 008 | Batch: 000 | Loss: 0.04286 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 008 | Batch: 100 | Loss: 0.03786 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 008 | Batch: 200 | Loss: 0.06453 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 008 | Batch: 300 | Loss: 0.06584 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 008 | Batch: 400 | Loss: 0.05506 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 008 | Batch: 000 | Loss: 0.04036 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 008 | Batch: 100 | Loss: 0.02066 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 008 | Batch: 200 | Loss: 0.01905 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 008 | Batch: 300 | Loss: 0.01735 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 008 | Batch: 400 | Loss: 0.03151 | Correct: 127/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:08:21,083 - INFO: Epoch: 008 | Validation Acc: 98.370 % | Historical Best: 98.460 %\n",
      "2022-09-25 01:08:21,083 - INFO: Epoch: 008 | Validation Acc: 98.370 % | Historical Best: 98.460 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 009 | Batch: 000 | Loss: 0.02593 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 009 | Batch: 100 | Loss: 0.02717 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 009 | Batch: 200 | Loss: 0.05542 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 009 | Batch: 300 | Loss: 0.01623 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 009 | Batch: 400 | Loss: 0.03914 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 009 | Batch: 000 | Loss: 0.05552 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 009 | Batch: 100 | Loss: 0.01191 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 009 | Batch: 200 | Loss: 0.05242 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 009 | Batch: 300 | Loss: 0.08849 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 009 | Batch: 400 | Loss: 0.07334 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 009 | Batch: 000 | Loss: 0.03658 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 009 | Batch: 100 | Loss: 0.02536 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 009 | Batch: 200 | Loss: 0.05907 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 009 | Batch: 300 | Loss: 0.04110 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 009 | Batch: 400 | Loss: 0.09088 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 009 | Batch: 000 | Loss: 0.05175 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 009 | Batch: 100 | Loss: 0.01140 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 009 | Batch: 200 | Loss: 0.00788 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 009 | Batch: 300 | Loss: 0.03821 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 009 | Batch: 400 | Loss: 0.04808 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 009 | Batch: 000 | Loss: 0.04161 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 009 | Batch: 100 | Loss: 0.04267 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 009 | Batch: 200 | Loss: 0.02142 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 009 | Batch: 300 | Loss: 0.04270 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 009 | Batch: 400 | Loss: 0.11358 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 009 | Batch: 000 | Loss: 0.01785 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 009 | Batch: 100 | Loss: 0.02031 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 009 | Batch: 200 | Loss: 0.01988 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 009 | Batch: 300 | Loss: 0.03493 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 009 | Batch: 400 | Loss: 0.02772 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 009 | Batch: 000 | Loss: 0.06665 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 009 | Batch: 100 | Loss: 0.02386 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 009 | Batch: 200 | Loss: 0.02402 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 009 | Batch: 300 | Loss: 0.04014 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 009 | Batch: 400 | Loss: 0.03435 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 009 | Batch: 000 | Loss: 0.04861 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 009 | Batch: 100 | Loss: 0.01626 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 009 | Batch: 200 | Loss: 0.02071 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 009 | Batch: 300 | Loss: 0.05688 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 009 | Batch: 400 | Loss: 0.03233 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 009 | Batch: 000 | Loss: 0.01917 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 009 | Batch: 100 | Loss: 0.04497 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 009 | Batch: 200 | Loss: 0.02219 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 009 | Batch: 300 | Loss: 0.03616 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 009 | Batch: 400 | Loss: 0.07670 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 009 | Batch: 000 | Loss: 0.06641 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 009 | Batch: 100 | Loss: 0.01130 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 009 | Batch: 200 | Loss: 0.01972 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 009 | Batch: 300 | Loss: 0.05593 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 009 | Batch: 400 | Loss: 0.02574 | Correct: 127/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:10:00,194 - INFO: Epoch: 009 | Validation Acc: 98.430 % | Historical Best: 98.460 %\n",
      "2022-09-25 01:10:00,194 - INFO: Epoch: 009 | Validation Acc: 98.430 % | Historical Best: 98.460 %\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_loader,\n",
    "    epochs=10,\n",
    "    test_loader=test_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d3496706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 000 | Batch: 000 | Loss: 2.29991 | Correct: 13/128\n",
      "Estimator: 000 | Epoch: 000 | Batch: 100 | Loss: 0.27077 | Correct: 118/128\n",
      "Estimator: 000 | Epoch: 000 | Batch: 200 | Loss: 0.29785 | Correct: 118/128\n",
      "Estimator: 000 | Epoch: 000 | Batch: 300 | Loss: 0.16451 | Correct: 122/128\n",
      "Estimator: 000 | Epoch: 000 | Batch: 400 | Loss: 0.21431 | Correct: 119/128\n",
      "Estimator: 001 | Epoch: 000 | Batch: 000 | Loss: 2.31173 | Correct: 17/128\n",
      "Estimator: 001 | Epoch: 000 | Batch: 100 | Loss: 0.30520 | Correct: 115/128\n",
      "Estimator: 001 | Epoch: 000 | Batch: 200 | Loss: 0.21295 | Correct: 121/128\n",
      "Estimator: 001 | Epoch: 000 | Batch: 300 | Loss: 0.16647 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 000 | Batch: 400 | Loss: 0.23819 | Correct: 118/128\n",
      "Estimator: 002 | Epoch: 000 | Batch: 000 | Loss: 2.31292 | Correct: 12/128\n",
      "Estimator: 002 | Epoch: 000 | Batch: 100 | Loss: 0.41693 | Correct: 112/128\n",
      "Estimator: 002 | Epoch: 000 | Batch: 200 | Loss: 0.17214 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 000 | Batch: 300 | Loss: 0.19334 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 000 | Batch: 400 | Loss: 0.13887 | Correct: 121/128\n",
      "Estimator: 003 | Epoch: 000 | Batch: 000 | Loss: 2.30613 | Correct: 12/128\n",
      "Estimator: 003 | Epoch: 000 | Batch: 100 | Loss: 0.28061 | Correct: 117/128\n",
      "Estimator: 003 | Epoch: 000 | Batch: 200 | Loss: 0.21537 | Correct: 119/128\n",
      "Estimator: 003 | Epoch: 000 | Batch: 300 | Loss: 0.15017 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 000 | Batch: 400 | Loss: 0.11121 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 000 | Batch: 000 | Loss: 2.31888 | Correct: 11/128\n",
      "Estimator: 004 | Epoch: 000 | Batch: 100 | Loss: 0.37023 | Correct: 115/128\n",
      "Estimator: 004 | Epoch: 000 | Batch: 200 | Loss: 0.23412 | Correct: 115/128\n",
      "Estimator: 004 | Epoch: 000 | Batch: 300 | Loss: 0.30696 | Correct: 115/128\n",
      "Estimator: 004 | Epoch: 000 | Batch: 400 | Loss: 0.19388 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 000 | Batch: 000 | Loss: 2.30647 | Correct: 9/128\n",
      "Estimator: 005 | Epoch: 000 | Batch: 100 | Loss: 0.33052 | Correct: 118/128\n",
      "Estimator: 005 | Epoch: 000 | Batch: 200 | Loss: 0.33846 | Correct: 116/128\n",
      "Estimator: 005 | Epoch: 000 | Batch: 300 | Loss: 0.23129 | Correct: 120/128\n",
      "Estimator: 005 | Epoch: 000 | Batch: 400 | Loss: 0.13762 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 000 | Batch: 000 | Loss: 2.30344 | Correct: 8/128\n",
      "Estimator: 006 | Epoch: 000 | Batch: 100 | Loss: 0.22896 | Correct: 120/128\n",
      "Estimator: 006 | Epoch: 000 | Batch: 200 | Loss: 0.33059 | Correct: 115/128\n",
      "Estimator: 006 | Epoch: 000 | Batch: 300 | Loss: 0.13870 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 000 | Batch: 400 | Loss: 0.22235 | Correct: 121/128\n",
      "Estimator: 007 | Epoch: 000 | Batch: 000 | Loss: 2.30539 | Correct: 9/128\n",
      "Estimator: 007 | Epoch: 000 | Batch: 100 | Loss: 0.19622 | Correct: 119/128\n",
      "Estimator: 007 | Epoch: 000 | Batch: 200 | Loss: 0.15839 | Correct: 121/128\n",
      "Estimator: 007 | Epoch: 000 | Batch: 300 | Loss: 0.12568 | Correct: 120/128\n",
      "Estimator: 007 | Epoch: 000 | Batch: 400 | Loss: 0.09332 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 000 | Batch: 000 | Loss: 2.31196 | Correct: 12/128\n",
      "Estimator: 008 | Epoch: 000 | Batch: 100 | Loss: 0.40455 | Correct: 111/128\n",
      "Estimator: 008 | Epoch: 000 | Batch: 200 | Loss: 0.18416 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 000 | Batch: 300 | Loss: 0.10623 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 000 | Batch: 400 | Loss: 0.13691 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 000 | Batch: 000 | Loss: 2.31832 | Correct: 13/128\n",
      "Estimator: 009 | Epoch: 000 | Batch: 100 | Loss: 0.19089 | Correct: 119/128\n",
      "Estimator: 009 | Epoch: 000 | Batch: 200 | Loss: 0.14897 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 000 | Batch: 300 | Loss: 0.27808 | Correct: 119/128\n",
      "Estimator: 009 | Epoch: 000 | Batch: 400 | Loss: 0.14103 | Correct: 122/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:11:37,945 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:11:37,945 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:11:37,994 - INFO: Epoch: 000 | Validation Acc: 96.360 % | Historical Best: 96.360 %\n",
      "2022-09-25 01:11:37,994 - INFO: Epoch: 000 | Validation Acc: 96.360 % | Historical Best: 96.360 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 001 | Batch: 000 | Loss: 0.05154 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 001 | Batch: 100 | Loss: 0.07950 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 001 | Batch: 200 | Loss: 0.13254 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 001 | Batch: 300 | Loss: 0.12003 | Correct: 123/128\n",
      "Estimator: 000 | Epoch: 001 | Batch: 400 | Loss: 0.05864 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 001 | Batch: 000 | Loss: 0.05924 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 001 | Batch: 100 | Loss: 0.14388 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 001 | Batch: 200 | Loss: 0.06688 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 001 | Batch: 300 | Loss: 0.04795 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 001 | Batch: 400 | Loss: 0.13768 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 001 | Batch: 000 | Loss: 0.06872 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 001 | Batch: 100 | Loss: 0.08845 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 001 | Batch: 200 | Loss: 0.09751 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 001 | Batch: 300 | Loss: 0.05631 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 001 | Batch: 400 | Loss: 0.17188 | Correct: 119/128\n",
      "Estimator: 003 | Epoch: 001 | Batch: 000 | Loss: 0.15180 | Correct: 120/128\n",
      "Estimator: 003 | Epoch: 001 | Batch: 100 | Loss: 0.05313 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 001 | Batch: 200 | Loss: 0.08263 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 001 | Batch: 300 | Loss: 0.13071 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 001 | Batch: 400 | Loss: 0.09827 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 001 | Batch: 000 | Loss: 0.14177 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 001 | Batch: 100 | Loss: 0.14849 | Correct: 121/128\n",
      "Estimator: 004 | Epoch: 001 | Batch: 200 | Loss: 0.11852 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 001 | Batch: 300 | Loss: 0.12387 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 001 | Batch: 400 | Loss: 0.04218 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 001 | Batch: 000 | Loss: 0.16375 | Correct: 121/128\n",
      "Estimator: 005 | Epoch: 001 | Batch: 100 | Loss: 0.15214 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 001 | Batch: 200 | Loss: 0.13125 | Correct: 120/128\n",
      "Estimator: 005 | Epoch: 001 | Batch: 300 | Loss: 0.05508 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 001 | Batch: 400 | Loss: 0.11137 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 001 | Batch: 000 | Loss: 0.11681 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 001 | Batch: 100 | Loss: 0.08773 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 001 | Batch: 200 | Loss: 0.14503 | Correct: 121/128\n",
      "Estimator: 006 | Epoch: 001 | Batch: 300 | Loss: 0.07449 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 001 | Batch: 400 | Loss: 0.08490 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 001 | Batch: 000 | Loss: 0.14026 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 001 | Batch: 100 | Loss: 0.08079 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 001 | Batch: 200 | Loss: 0.16238 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 001 | Batch: 300 | Loss: 0.12241 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 001 | Batch: 400 | Loss: 0.07081 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 001 | Batch: 000 | Loss: 0.10078 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 001 | Batch: 100 | Loss: 0.10015 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 001 | Batch: 200 | Loss: 0.13369 | Correct: 121/128\n",
      "Estimator: 008 | Epoch: 001 | Batch: 300 | Loss: 0.06878 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 001 | Batch: 400 | Loss: 0.14286 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 001 | Batch: 000 | Loss: 0.09291 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 001 | Batch: 100 | Loss: 0.13492 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 001 | Batch: 200 | Loss: 0.09424 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 001 | Batch: 300 | Loss: 0.14705 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 001 | Batch: 400 | Loss: 0.07944 | Correct: 126/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:13:16,293 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:13:16,293 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:13:16,398 - INFO: Epoch: 001 | Validation Acc: 97.440 % | Historical Best: 97.440 %\n",
      "2022-09-25 01:13:16,398 - INFO: Epoch: 001 | Validation Acc: 97.440 % | Historical Best: 97.440 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 002 | Batch: 000 | Loss: 0.04396 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 002 | Batch: 100 | Loss: 0.04602 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 002 | Batch: 200 | Loss: 0.05791 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 002 | Batch: 300 | Loss: 0.06794 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 002 | Batch: 400 | Loss: 0.04418 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 002 | Batch: 000 | Loss: 0.04736 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 002 | Batch: 100 | Loss: 0.07517 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 002 | Batch: 200 | Loss: 0.04894 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 002 | Batch: 300 | Loss: 0.15217 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 002 | Batch: 400 | Loss: 0.08449 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 002 | Batch: 000 | Loss: 0.12853 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 002 | Batch: 100 | Loss: 0.11609 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 002 | Batch: 200 | Loss: 0.09525 | Correct: 122/128\n",
      "Estimator: 002 | Epoch: 002 | Batch: 300 | Loss: 0.14419 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 002 | Batch: 400 | Loss: 0.13131 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 002 | Batch: 000 | Loss: 0.17757 | Correct: 122/128\n",
      "Estimator: 003 | Epoch: 002 | Batch: 100 | Loss: 0.08316 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 002 | Batch: 200 | Loss: 0.14193 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 002 | Batch: 300 | Loss: 0.07979 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 002 | Batch: 400 | Loss: 0.05932 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 002 | Batch: 000 | Loss: 0.09210 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 002 | Batch: 100 | Loss: 0.06318 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 002 | Batch: 200 | Loss: 0.02579 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 002 | Batch: 300 | Loss: 0.06131 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 002 | Batch: 400 | Loss: 0.11046 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 002 | Batch: 000 | Loss: 0.14096 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 002 | Batch: 100 | Loss: 0.09635 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 002 | Batch: 200 | Loss: 0.15195 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 002 | Batch: 300 | Loss: 0.12910 | Correct: 122/128\n",
      "Estimator: 005 | Epoch: 002 | Batch: 400 | Loss: 0.05284 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 002 | Batch: 000 | Loss: 0.08683 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 002 | Batch: 100 | Loss: 0.06588 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 002 | Batch: 200 | Loss: 0.18014 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 002 | Batch: 300 | Loss: 0.10655 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 002 | Batch: 400 | Loss: 0.16598 | Correct: 121/128\n",
      "Estimator: 007 | Epoch: 002 | Batch: 000 | Loss: 0.10642 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 002 | Batch: 100 | Loss: 0.16369 | Correct: 122/128\n",
      "Estimator: 007 | Epoch: 002 | Batch: 200 | Loss: 0.06673 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 002 | Batch: 300 | Loss: 0.18133 | Correct: 118/128\n",
      "Estimator: 007 | Epoch: 002 | Batch: 400 | Loss: 0.04094 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 002 | Batch: 000 | Loss: 0.08712 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 002 | Batch: 100 | Loss: 0.07032 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 002 | Batch: 200 | Loss: 0.05145 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 002 | Batch: 300 | Loss: 0.03558 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 002 | Batch: 400 | Loss: 0.14185 | Correct: 122/128\n",
      "Estimator: 009 | Epoch: 002 | Batch: 000 | Loss: 0.08300 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 002 | Batch: 100 | Loss: 0.16887 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 002 | Batch: 200 | Loss: 0.12382 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 002 | Batch: 300 | Loss: 0.07318 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 002 | Batch: 400 | Loss: 0.04141 | Correct: 127/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:14:54,859 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:14:54,859 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:14:54,974 - INFO: Epoch: 002 | Validation Acc: 97.980 % | Historical Best: 97.980 %\n",
      "2022-09-25 01:14:54,974 - INFO: Epoch: 002 | Validation Acc: 97.980 % | Historical Best: 97.980 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 003 | Batch: 000 | Loss: 0.05440 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 003 | Batch: 100 | Loss: 0.05420 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 003 | Batch: 200 | Loss: 0.03642 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 003 | Batch: 300 | Loss: 0.02598 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 003 | Batch: 400 | Loss: 0.06019 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 003 | Batch: 000 | Loss: 0.06457 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 003 | Batch: 100 | Loss: 0.07925 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 003 | Batch: 200 | Loss: 0.08938 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 003 | Batch: 300 | Loss: 0.04867 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 003 | Batch: 400 | Loss: 0.06847 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 003 | Batch: 000 | Loss: 0.06969 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 003 | Batch: 100 | Loss: 0.09918 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 003 | Batch: 200 | Loss: 0.13905 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 003 | Batch: 300 | Loss: 0.04957 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 003 | Batch: 400 | Loss: 0.04677 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 003 | Batch: 000 | Loss: 0.05316 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 003 | Batch: 100 | Loss: 0.02671 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 003 | Batch: 200 | Loss: 0.05488 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 003 | Batch: 300 | Loss: 0.06821 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 003 | Batch: 400 | Loss: 0.07321 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 003 | Batch: 000 | Loss: 0.08469 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 003 | Batch: 100 | Loss: 0.04002 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 003 | Batch: 200 | Loss: 0.06069 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 003 | Batch: 300 | Loss: 0.05423 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 003 | Batch: 400 | Loss: 0.03093 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 003 | Batch: 000 | Loss: 0.13425 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 003 | Batch: 100 | Loss: 0.04316 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 003 | Batch: 200 | Loss: 0.05459 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 003 | Batch: 300 | Loss: 0.02840 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 003 | Batch: 400 | Loss: 0.03543 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 003 | Batch: 000 | Loss: 0.13766 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 003 | Batch: 100 | Loss: 0.09988 | Correct: 122/128\n",
      "Estimator: 006 | Epoch: 003 | Batch: 200 | Loss: 0.07106 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 003 | Batch: 300 | Loss: 0.04715 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 003 | Batch: 400 | Loss: 0.08113 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 003 | Batch: 000 | Loss: 0.06723 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 003 | Batch: 100 | Loss: 0.11737 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 003 | Batch: 200 | Loss: 0.11987 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 003 | Batch: 300 | Loss: 0.12145 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 003 | Batch: 400 | Loss: 0.07350 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 003 | Batch: 000 | Loss: 0.02952 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 003 | Batch: 100 | Loss: 0.03108 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 003 | Batch: 200 | Loss: 0.01572 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 003 | Batch: 300 | Loss: 0.11962 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 003 | Batch: 400 | Loss: 0.02323 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 003 | Batch: 000 | Loss: 0.05842 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 003 | Batch: 100 | Loss: 0.08441 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 003 | Batch: 200 | Loss: 0.06910 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 003 | Batch: 300 | Loss: 0.04107 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 003 | Batch: 400 | Loss: 0.01899 | Correct: 128/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:16:33,265 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:16:33,265 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:16:33,322 - INFO: Epoch: 003 | Validation Acc: 98.120 % | Historical Best: 98.120 %\n",
      "2022-09-25 01:16:33,322 - INFO: Epoch: 003 | Validation Acc: 98.120 % | Historical Best: 98.120 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 004 | Batch: 000 | Loss: 0.01761 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 004 | Batch: 100 | Loss: 0.03275 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 004 | Batch: 200 | Loss: 0.03932 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 004 | Batch: 300 | Loss: 0.04852 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 004 | Batch: 400 | Loss: 0.08257 | Correct: 121/128\n",
      "Estimator: 001 | Epoch: 004 | Batch: 000 | Loss: 0.04185 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 004 | Batch: 100 | Loss: 0.03043 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 004 | Batch: 200 | Loss: 0.03360 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 004 | Batch: 300 | Loss: 0.05220 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 004 | Batch: 400 | Loss: 0.04805 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 004 | Batch: 000 | Loss: 0.06986 | Correct: 123/128\n",
      "Estimator: 002 | Epoch: 004 | Batch: 100 | Loss: 0.03711 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 004 | Batch: 200 | Loss: 0.02304 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 004 | Batch: 300 | Loss: 0.05998 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 004 | Batch: 400 | Loss: 0.07235 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 004 | Batch: 000 | Loss: 0.02620 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 004 | Batch: 100 | Loss: 0.06905 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 004 | Batch: 200 | Loss: 0.04458 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 004 | Batch: 300 | Loss: 0.03704 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 004 | Batch: 400 | Loss: 0.08056 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 004 | Batch: 000 | Loss: 0.01632 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 004 | Batch: 100 | Loss: 0.07886 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 004 | Batch: 200 | Loss: 0.07800 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 004 | Batch: 300 | Loss: 0.11280 | Correct: 123/128\n",
      "Estimator: 004 | Epoch: 004 | Batch: 400 | Loss: 0.04710 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 004 | Batch: 000 | Loss: 0.06065 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 004 | Batch: 100 | Loss: 0.07357 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 004 | Batch: 200 | Loss: 0.02644 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 004 | Batch: 300 | Loss: 0.03621 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 004 | Batch: 400 | Loss: 0.02013 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 004 | Batch: 000 | Loss: 0.08214 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 004 | Batch: 100 | Loss: 0.07782 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 004 | Batch: 200 | Loss: 0.03381 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 004 | Batch: 300 | Loss: 0.08421 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 004 | Batch: 400 | Loss: 0.11144 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 004 | Batch: 000 | Loss: 0.07691 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 004 | Batch: 100 | Loss: 0.01963 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 004 | Batch: 200 | Loss: 0.11423 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 004 | Batch: 300 | Loss: 0.02050 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 004 | Batch: 400 | Loss: 0.09267 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 004 | Batch: 000 | Loss: 0.08040 | Correct: 122/128\n",
      "Estimator: 008 | Epoch: 004 | Batch: 100 | Loss: 0.02880 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 004 | Batch: 200 | Loss: 0.07727 | Correct: 123/128\n",
      "Estimator: 008 | Epoch: 004 | Batch: 300 | Loss: 0.02082 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 004 | Batch: 400 | Loss: 0.09388 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 004 | Batch: 000 | Loss: 0.00904 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 004 | Batch: 100 | Loss: 0.06490 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 004 | Batch: 200 | Loss: 0.04432 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 004 | Batch: 300 | Loss: 0.05688 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 004 | Batch: 400 | Loss: 0.06743 | Correct: 124/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:18:11,540 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:18:11,540 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:18:11,656 - INFO: Epoch: 004 | Validation Acc: 98.270 % | Historical Best: 98.270 %\n",
      "2022-09-25 01:18:11,656 - INFO: Epoch: 004 | Validation Acc: 98.270 % | Historical Best: 98.270 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 005 | Batch: 000 | Loss: 0.06606 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 005 | Batch: 100 | Loss: 0.02890 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 005 | Batch: 200 | Loss: 0.05159 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 005 | Batch: 300 | Loss: 0.05390 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 005 | Batch: 400 | Loss: 0.04719 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 005 | Batch: 000 | Loss: 0.02379 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 005 | Batch: 100 | Loss: 0.03235 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 005 | Batch: 200 | Loss: 0.07365 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 005 | Batch: 300 | Loss: 0.01433 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 005 | Batch: 400 | Loss: 0.06934 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 005 | Batch: 000 | Loss: 0.01755 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 005 | Batch: 100 | Loss: 0.05278 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 005 | Batch: 200 | Loss: 0.07185 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 005 | Batch: 300 | Loss: 0.03642 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 005 | Batch: 400 | Loss: 0.01818 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 005 | Batch: 000 | Loss: 0.10557 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 005 | Batch: 100 | Loss: 0.05267 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 005 | Batch: 200 | Loss: 0.03224 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 005 | Batch: 300 | Loss: 0.05375 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 005 | Batch: 400 | Loss: 0.05514 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 005 | Batch: 000 | Loss: 0.01457 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 005 | Batch: 100 | Loss: 0.01841 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 005 | Batch: 200 | Loss: 0.03585 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 005 | Batch: 300 | Loss: 0.03433 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 005 | Batch: 400 | Loss: 0.03979 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 005 | Batch: 000 | Loss: 0.04141 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 005 | Batch: 100 | Loss: 0.03777 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 005 | Batch: 200 | Loss: 0.04413 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 005 | Batch: 300 | Loss: 0.07405 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 005 | Batch: 400 | Loss: 0.04103 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 005 | Batch: 000 | Loss: 0.01895 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 005 | Batch: 100 | Loss: 0.02138 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 005 | Batch: 200 | Loss: 0.04650 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 005 | Batch: 300 | Loss: 0.05849 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 005 | Batch: 400 | Loss: 0.02618 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 005 | Batch: 000 | Loss: 0.05661 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 005 | Batch: 100 | Loss: 0.05021 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 005 | Batch: 200 | Loss: 0.09523 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 005 | Batch: 300 | Loss: 0.04934 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 005 | Batch: 400 | Loss: 0.09971 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 005 | Batch: 000 | Loss: 0.05515 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 005 | Batch: 100 | Loss: 0.07707 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 005 | Batch: 200 | Loss: 0.05749 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 005 | Batch: 300 | Loss: 0.04563 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 005 | Batch: 400 | Loss: 0.02092 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 005 | Batch: 000 | Loss: 0.07571 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 005 | Batch: 100 | Loss: 0.03521 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 005 | Batch: 200 | Loss: 0.03544 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 005 | Batch: 300 | Loss: 0.04162 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 005 | Batch: 400 | Loss: 0.05651 | Correct: 126/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:19:49,744 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:19:49,744 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:19:49,858 - INFO: Epoch: 005 | Validation Acc: 98.300 % | Historical Best: 98.300 %\n",
      "2022-09-25 01:19:49,858 - INFO: Epoch: 005 | Validation Acc: 98.300 % | Historical Best: 98.300 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 006 | Batch: 000 | Loss: 0.00791 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 006 | Batch: 100 | Loss: 0.04383 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 006 | Batch: 200 | Loss: 0.04217 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 006 | Batch: 300 | Loss: 0.03430 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 006 | Batch: 400 | Loss: 0.01106 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 006 | Batch: 000 | Loss: 0.01636 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 006 | Batch: 100 | Loss: 0.03922 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 006 | Batch: 200 | Loss: 0.07922 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 006 | Batch: 300 | Loss: 0.03205 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 006 | Batch: 400 | Loss: 0.05575 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 006 | Batch: 000 | Loss: 0.08757 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 006 | Batch: 100 | Loss: 0.03887 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 006 | Batch: 200 | Loss: 0.06978 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 006 | Batch: 300 | Loss: 0.04712 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 006 | Batch: 400 | Loss: 0.09675 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 006 | Batch: 000 | Loss: 0.01812 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 006 | Batch: 100 | Loss: 0.02091 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 006 | Batch: 200 | Loss: 0.04103 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 006 | Batch: 300 | Loss: 0.04210 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 006 | Batch: 400 | Loss: 0.04216 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 006 | Batch: 000 | Loss: 0.03610 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 006 | Batch: 100 | Loss: 0.01961 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 006 | Batch: 200 | Loss: 0.10937 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 006 | Batch: 300 | Loss: 0.02713 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 006 | Batch: 400 | Loss: 0.08116 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 006 | Batch: 000 | Loss: 0.01339 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 006 | Batch: 100 | Loss: 0.02226 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 006 | Batch: 200 | Loss: 0.10099 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 006 | Batch: 300 | Loss: 0.01507 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 006 | Batch: 400 | Loss: 0.03850 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 006 | Batch: 000 | Loss: 0.01464 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 006 | Batch: 100 | Loss: 0.04395 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 006 | Batch: 200 | Loss: 0.09322 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 006 | Batch: 300 | Loss: 0.09418 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 006 | Batch: 400 | Loss: 0.02438 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 006 | Batch: 000 | Loss: 0.02549 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 006 | Batch: 100 | Loss: 0.10081 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 006 | Batch: 200 | Loss: 0.03695 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 006 | Batch: 300 | Loss: 0.08683 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 006 | Batch: 400 | Loss: 0.06802 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 006 | Batch: 000 | Loss: 0.06729 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 006 | Batch: 100 | Loss: 0.09826 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 006 | Batch: 200 | Loss: 0.03141 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 006 | Batch: 300 | Loss: 0.08917 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 006 | Batch: 400 | Loss: 0.05253 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 006 | Batch: 000 | Loss: 0.02914 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 006 | Batch: 100 | Loss: 0.01819 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 006 | Batch: 200 | Loss: 0.05656 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 006 | Batch: 300 | Loss: 0.02983 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 006 | Batch: 400 | Loss: 0.04006 | Correct: 126/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:21:28,493 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:21:28,493 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:21:28,598 - INFO: Epoch: 006 | Validation Acc: 98.360 % | Historical Best: 98.360 %\n",
      "2022-09-25 01:21:28,598 - INFO: Epoch: 006 | Validation Acc: 98.360 % | Historical Best: 98.360 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 007 | Batch: 000 | Loss: 0.04186 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 007 | Batch: 100 | Loss: 0.04142 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 007 | Batch: 200 | Loss: 0.00794 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 007 | Batch: 300 | Loss: 0.02949 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 007 | Batch: 400 | Loss: 0.05006 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 007 | Batch: 000 | Loss: 0.09855 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 007 | Batch: 100 | Loss: 0.01928 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 007 | Batch: 200 | Loss: 0.02480 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 007 | Batch: 300 | Loss: 0.02109 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 007 | Batch: 400 | Loss: 0.04181 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 007 | Batch: 000 | Loss: 0.02241 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 007 | Batch: 100 | Loss: 0.09041 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 007 | Batch: 200 | Loss: 0.02065 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 007 | Batch: 300 | Loss: 0.02611 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 007 | Batch: 400 | Loss: 0.08556 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 007 | Batch: 000 | Loss: 0.02048 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 007 | Batch: 100 | Loss: 0.00634 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 007 | Batch: 200 | Loss: 0.01354 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 007 | Batch: 300 | Loss: 0.06120 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 007 | Batch: 400 | Loss: 0.01679 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 007 | Batch: 000 | Loss: 0.03534 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 007 | Batch: 100 | Loss: 0.03193 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 007 | Batch: 200 | Loss: 0.01311 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 007 | Batch: 300 | Loss: 0.04257 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 007 | Batch: 400 | Loss: 0.07246 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 007 | Batch: 000 | Loss: 0.07863 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 007 | Batch: 100 | Loss: 0.05828 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 007 | Batch: 200 | Loss: 0.02082 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 007 | Batch: 300 | Loss: 0.02160 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 007 | Batch: 400 | Loss: 0.07912 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 007 | Batch: 000 | Loss: 0.06720 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 007 | Batch: 100 | Loss: 0.01923 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 007 | Batch: 200 | Loss: 0.06662 | Correct: 123/128\n",
      "Estimator: 006 | Epoch: 007 | Batch: 300 | Loss: 0.04065 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 007 | Batch: 400 | Loss: 0.02977 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 007 | Batch: 000 | Loss: 0.05334 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 007 | Batch: 100 | Loss: 0.03121 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 007 | Batch: 200 | Loss: 0.03255 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 007 | Batch: 300 | Loss: 0.02625 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 007 | Batch: 400 | Loss: 0.06251 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 007 | Batch: 000 | Loss: 0.08086 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 007 | Batch: 100 | Loss: 0.06837 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 007 | Batch: 200 | Loss: 0.07304 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 007 | Batch: 300 | Loss: 0.08647 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 007 | Batch: 400 | Loss: 0.08789 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 007 | Batch: 000 | Loss: 0.01656 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 007 | Batch: 100 | Loss: 0.03294 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 007 | Batch: 200 | Loss: 0.09528 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 007 | Batch: 300 | Loss: 0.02222 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 007 | Batch: 400 | Loss: 0.02725 | Correct: 126/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:23:07,908 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:23:07,908 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:23:08,022 - INFO: Epoch: 007 | Validation Acc: 98.390 % | Historical Best: 98.390 %\n",
      "2022-09-25 01:23:08,022 - INFO: Epoch: 007 | Validation Acc: 98.390 % | Historical Best: 98.390 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 008 | Batch: 000 | Loss: 0.01876 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 008 | Batch: 100 | Loss: 0.02442 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 008 | Batch: 200 | Loss: 0.00978 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 008 | Batch: 300 | Loss: 0.06371 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 008 | Batch: 400 | Loss: 0.08549 | Correct: 122/128\n",
      "Estimator: 001 | Epoch: 008 | Batch: 000 | Loss: 0.06574 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 008 | Batch: 100 | Loss: 0.09517 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 008 | Batch: 200 | Loss: 0.02738 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 008 | Batch: 300 | Loss: 0.06158 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 008 | Batch: 400 | Loss: 0.04037 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 008 | Batch: 000 | Loss: 0.01105 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 008 | Batch: 100 | Loss: 0.02794 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 008 | Batch: 200 | Loss: 0.02938 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 008 | Batch: 300 | Loss: 0.01908 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 008 | Batch: 400 | Loss: 0.01679 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 008 | Batch: 000 | Loss: 0.01250 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 008 | Batch: 100 | Loss: 0.02675 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 008 | Batch: 200 | Loss: 0.01729 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 008 | Batch: 300 | Loss: 0.04602 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 008 | Batch: 400 | Loss: 0.07221 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 008 | Batch: 000 | Loss: 0.02025 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 008 | Batch: 100 | Loss: 0.05387 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 008 | Batch: 200 | Loss: 0.03005 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 008 | Batch: 300 | Loss: 0.05809 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 008 | Batch: 400 | Loss: 0.09876 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 008 | Batch: 000 | Loss: 0.03708 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 008 | Batch: 100 | Loss: 0.02672 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 008 | Batch: 200 | Loss: 0.03478 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 008 | Batch: 300 | Loss: 0.01936 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 008 | Batch: 400 | Loss: 0.00975 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 008 | Batch: 000 | Loss: 0.01696 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 008 | Batch: 100 | Loss: 0.05083 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 008 | Batch: 200 | Loss: 0.09854 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 008 | Batch: 300 | Loss: 0.02964 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 008 | Batch: 400 | Loss: 0.03763 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 008 | Batch: 000 | Loss: 0.06919 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 008 | Batch: 100 | Loss: 0.04953 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 008 | Batch: 200 | Loss: 0.04662 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 008 | Batch: 300 | Loss: 0.03079 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 008 | Batch: 400 | Loss: 0.03465 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 008 | Batch: 000 | Loss: 0.03901 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 008 | Batch: 100 | Loss: 0.02055 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 008 | Batch: 200 | Loss: 0.04295 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 008 | Batch: 300 | Loss: 0.02839 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 008 | Batch: 400 | Loss: 0.05625 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 008 | Batch: 000 | Loss: 0.02771 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 008 | Batch: 100 | Loss: 0.07098 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 008 | Batch: 200 | Loss: 0.03463 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 008 | Batch: 300 | Loss: 0.03658 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 008 | Batch: 400 | Loss: 0.00931 | Correct: 128/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:24:47,702 - INFO: Epoch: 008 | Validation Acc: 98.320 % | Historical Best: 98.390 %\n",
      "2022-09-25 01:24:47,702 - INFO: Epoch: 008 | Validation Acc: 98.320 % | Historical Best: 98.390 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 009 | Batch: 000 | Loss: 0.05758 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 009 | Batch: 100 | Loss: 0.02152 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 009 | Batch: 200 | Loss: 0.01098 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 009 | Batch: 300 | Loss: 0.01422 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 009 | Batch: 400 | Loss: 0.08122 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 009 | Batch: 000 | Loss: 0.04531 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 009 | Batch: 100 | Loss: 0.04423 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 009 | Batch: 200 | Loss: 0.07531 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 009 | Batch: 300 | Loss: 0.06649 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 009 | Batch: 400 | Loss: 0.03662 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 009 | Batch: 000 | Loss: 0.00994 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 009 | Batch: 100 | Loss: 0.05905 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 009 | Batch: 200 | Loss: 0.05801 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 009 | Batch: 300 | Loss: 0.03283 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 009 | Batch: 400 | Loss: 0.03698 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 009 | Batch: 000 | Loss: 0.03024 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 009 | Batch: 100 | Loss: 0.08911 | Correct: 123/128\n",
      "Estimator: 003 | Epoch: 009 | Batch: 200 | Loss: 0.02075 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 009 | Batch: 300 | Loss: 0.08065 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 009 | Batch: 400 | Loss: 0.05202 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 009 | Batch: 000 | Loss: 0.01782 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 009 | Batch: 100 | Loss: 0.03025 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 009 | Batch: 200 | Loss: 0.02341 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 009 | Batch: 300 | Loss: 0.02426 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 009 | Batch: 400 | Loss: 0.05803 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 009 | Batch: 000 | Loss: 0.04264 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 009 | Batch: 100 | Loss: 0.01382 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 009 | Batch: 200 | Loss: 0.05235 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 009 | Batch: 300 | Loss: 0.01393 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 009 | Batch: 400 | Loss: 0.02782 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 009 | Batch: 000 | Loss: 0.04931 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 009 | Batch: 100 | Loss: 0.01030 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 009 | Batch: 200 | Loss: 0.03050 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 009 | Batch: 300 | Loss: 0.02708 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 009 | Batch: 400 | Loss: 0.12586 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 009 | Batch: 000 | Loss: 0.08680 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 009 | Batch: 100 | Loss: 0.00747 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 009 | Batch: 200 | Loss: 0.01005 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 009 | Batch: 300 | Loss: 0.03639 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 009 | Batch: 400 | Loss: 0.04123 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 009 | Batch: 000 | Loss: 0.06662 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 009 | Batch: 100 | Loss: 0.00513 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 009 | Batch: 200 | Loss: 0.02300 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 009 | Batch: 300 | Loss: 0.01491 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 009 | Batch: 400 | Loss: 0.03133 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 009 | Batch: 000 | Loss: 0.00570 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 009 | Batch: 100 | Loss: 0.02909 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 009 | Batch: 200 | Loss: 0.02384 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 009 | Batch: 300 | Loss: 0.00870 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 009 | Batch: 400 | Loss: 0.03136 | Correct: 126/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:26:28,197 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:26:28,197 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:26:28,210 - INFO: Epoch: 009 | Validation Acc: 98.450 % | Historical Best: 98.450 %\n",
      "2022-09-25 01:26:28,210 - INFO: Epoch: 009 | Validation Acc: 98.450 % | Historical Best: 98.450 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 010 | Batch: 000 | Loss: 0.04607 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 010 | Batch: 100 | Loss: 0.01316 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 010 | Batch: 200 | Loss: 0.03406 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 010 | Batch: 300 | Loss: 0.01517 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 010 | Batch: 400 | Loss: 0.06723 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 010 | Batch: 000 | Loss: 0.01134 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 010 | Batch: 100 | Loss: 0.05019 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 010 | Batch: 200 | Loss: 0.07195 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 010 | Batch: 300 | Loss: 0.08029 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 010 | Batch: 400 | Loss: 0.07062 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 010 | Batch: 000 | Loss: 0.01875 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 010 | Batch: 100 | Loss: 0.03494 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 010 | Batch: 200 | Loss: 0.02128 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 010 | Batch: 300 | Loss: 0.05555 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 010 | Batch: 400 | Loss: 0.04524 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 010 | Batch: 000 | Loss: 0.01912 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 010 | Batch: 100 | Loss: 0.03122 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 010 | Batch: 200 | Loss: 0.01178 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 010 | Batch: 300 | Loss: 0.00590 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 010 | Batch: 400 | Loss: 0.02233 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 010 | Batch: 000 | Loss: 0.01359 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 010 | Batch: 100 | Loss: 0.01533 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 010 | Batch: 200 | Loss: 0.04482 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 010 | Batch: 300 | Loss: 0.05996 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 010 | Batch: 400 | Loss: 0.04710 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 010 | Batch: 000 | Loss: 0.04525 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 010 | Batch: 100 | Loss: 0.08563 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 010 | Batch: 200 | Loss: 0.02218 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 010 | Batch: 300 | Loss: 0.03202 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 010 | Batch: 400 | Loss: 0.06210 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 010 | Batch: 000 | Loss: 0.02940 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 010 | Batch: 100 | Loss: 0.01232 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 010 | Batch: 200 | Loss: 0.06979 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 010 | Batch: 300 | Loss: 0.07507 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 010 | Batch: 400 | Loss: 0.08515 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 010 | Batch: 000 | Loss: 0.03364 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 010 | Batch: 100 | Loss: 0.01605 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 010 | Batch: 200 | Loss: 0.01307 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 010 | Batch: 300 | Loss: 0.02935 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 010 | Batch: 400 | Loss: 0.02566 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 010 | Batch: 000 | Loss: 0.04902 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 010 | Batch: 100 | Loss: 0.02432 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 010 | Batch: 200 | Loss: 0.00587 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 010 | Batch: 300 | Loss: 0.05054 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 010 | Batch: 400 | Loss: 0.01047 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 010 | Batch: 000 | Loss: 0.05984 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 010 | Batch: 100 | Loss: 0.00969 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 010 | Batch: 200 | Loss: 0.03501 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 010 | Batch: 300 | Loss: 0.02470 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 010 | Batch: 400 | Loss: 0.01953 | Correct: 127/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:28:07,452 - INFO: Epoch: 010 | Validation Acc: 98.420 % | Historical Best: 98.450 %\n",
      "2022-09-25 01:28:07,452 - INFO: Epoch: 010 | Validation Acc: 98.420 % | Historical Best: 98.450 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 011 | Batch: 000 | Loss: 0.06554 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 011 | Batch: 100 | Loss: 0.01421 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 011 | Batch: 200 | Loss: 0.04037 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 011 | Batch: 300 | Loss: 0.03732 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 011 | Batch: 400 | Loss: 0.01117 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 011 | Batch: 000 | Loss: 0.00653 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 011 | Batch: 100 | Loss: 0.00983 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 011 | Batch: 200 | Loss: 0.01361 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 011 | Batch: 300 | Loss: 0.01550 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 011 | Batch: 400 | Loss: 0.05873 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 011 | Batch: 000 | Loss: 0.01080 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 011 | Batch: 100 | Loss: 0.02558 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 011 | Batch: 200 | Loss: 0.01230 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 011 | Batch: 300 | Loss: 0.04259 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 011 | Batch: 400 | Loss: 0.01898 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 011 | Batch: 000 | Loss: 0.02763 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 011 | Batch: 100 | Loss: 0.02777 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 011 | Batch: 200 | Loss: 0.01489 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 011 | Batch: 300 | Loss: 0.02860 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 011 | Batch: 400 | Loss: 0.07238 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 011 | Batch: 000 | Loss: 0.01133 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 011 | Batch: 100 | Loss: 0.01247 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 011 | Batch: 200 | Loss: 0.03178 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 011 | Batch: 300 | Loss: 0.06831 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 011 | Batch: 400 | Loss: 0.01748 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 011 | Batch: 000 | Loss: 0.03852 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 011 | Batch: 100 | Loss: 0.02752 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 011 | Batch: 200 | Loss: 0.02434 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 011 | Batch: 300 | Loss: 0.00978 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 011 | Batch: 400 | Loss: 0.02064 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 011 | Batch: 000 | Loss: 0.02465 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 011 | Batch: 100 | Loss: 0.04990 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 011 | Batch: 200 | Loss: 0.06659 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 011 | Batch: 300 | Loss: 0.02500 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 011 | Batch: 400 | Loss: 0.02277 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 011 | Batch: 000 | Loss: 0.01995 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 011 | Batch: 100 | Loss: 0.01631 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 011 | Batch: 200 | Loss: 0.01778 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 011 | Batch: 300 | Loss: 0.07829 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 011 | Batch: 400 | Loss: 0.01858 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 011 | Batch: 000 | Loss: 0.02641 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 011 | Batch: 100 | Loss: 0.02821 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 011 | Batch: 200 | Loss: 0.03007 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 011 | Batch: 300 | Loss: 0.01436 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 011 | Batch: 400 | Loss: 0.06309 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 011 | Batch: 000 | Loss: 0.02298 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 011 | Batch: 100 | Loss: 0.01448 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 011 | Batch: 200 | Loss: 0.00635 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 011 | Batch: 300 | Loss: 0.03896 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 011 | Batch: 400 | Loss: 0.04797 | Correct: 126/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:29:46,196 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:29:46,196 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:29:46,310 - INFO: Epoch: 011 | Validation Acc: 98.470 % | Historical Best: 98.470 %\n",
      "2022-09-25 01:29:46,310 - INFO: Epoch: 011 | Validation Acc: 98.470 % | Historical Best: 98.470 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 012 | Batch: 000 | Loss: 0.01719 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 012 | Batch: 100 | Loss: 0.01655 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 012 | Batch: 200 | Loss: 0.01270 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 012 | Batch: 300 | Loss: 0.00988 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 012 | Batch: 400 | Loss: 0.03360 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 012 | Batch: 000 | Loss: 0.01926 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 012 | Batch: 100 | Loss: 0.01275 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 012 | Batch: 200 | Loss: 0.03551 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 012 | Batch: 300 | Loss: 0.05351 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 012 | Batch: 400 | Loss: 0.01044 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 012 | Batch: 000 | Loss: 0.05797 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 012 | Batch: 100 | Loss: 0.02251 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 012 | Batch: 200 | Loss: 0.01726 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 012 | Batch: 300 | Loss: 0.08136 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 012 | Batch: 400 | Loss: 0.02383 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 012 | Batch: 000 | Loss: 0.01979 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 012 | Batch: 100 | Loss: 0.03789 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 012 | Batch: 200 | Loss: 0.06816 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 012 | Batch: 300 | Loss: 0.04798 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 012 | Batch: 400 | Loss: 0.05814 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 012 | Batch: 000 | Loss: 0.03054 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 012 | Batch: 100 | Loss: 0.01214 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 012 | Batch: 200 | Loss: 0.03969 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 012 | Batch: 300 | Loss: 0.04846 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 012 | Batch: 400 | Loss: 0.02223 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 012 | Batch: 000 | Loss: 0.05925 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 012 | Batch: 100 | Loss: 0.03906 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 012 | Batch: 200 | Loss: 0.01542 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 012 | Batch: 300 | Loss: 0.02053 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 012 | Batch: 400 | Loss: 0.03551 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 012 | Batch: 000 | Loss: 0.00685 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 012 | Batch: 100 | Loss: 0.04265 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 012 | Batch: 200 | Loss: 0.02320 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 012 | Batch: 300 | Loss: 0.04708 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 012 | Batch: 400 | Loss: 0.02053 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 012 | Batch: 000 | Loss: 0.04086 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 012 | Batch: 100 | Loss: 0.01143 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 012 | Batch: 200 | Loss: 0.02832 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 012 | Batch: 300 | Loss: 0.03344 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 012 | Batch: 400 | Loss: 0.01005 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 012 | Batch: 000 | Loss: 0.02664 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 012 | Batch: 100 | Loss: 0.02619 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 012 | Batch: 200 | Loss: 0.00957 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 012 | Batch: 300 | Loss: 0.03912 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 012 | Batch: 400 | Loss: 0.03594 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 012 | Batch: 000 | Loss: 0.01723 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 012 | Batch: 100 | Loss: 0.02012 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 012 | Batch: 200 | Loss: 0.02556 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 012 | Batch: 300 | Loss: 0.02119 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 012 | Batch: 400 | Loss: 0.03627 | Correct: 126/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:31:25,395 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:31:25,395 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:31:25,509 - INFO: Epoch: 012 | Validation Acc: 98.490 % | Historical Best: 98.490 %\n",
      "2022-09-25 01:31:25,509 - INFO: Epoch: 012 | Validation Acc: 98.490 % | Historical Best: 98.490 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 013 | Batch: 000 | Loss: 0.02248 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 013 | Batch: 100 | Loss: 0.02198 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 013 | Batch: 200 | Loss: 0.02423 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 013 | Batch: 300 | Loss: 0.05133 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 013 | Batch: 400 | Loss: 0.02832 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 013 | Batch: 000 | Loss: 0.02338 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 013 | Batch: 100 | Loss: 0.03320 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 013 | Batch: 200 | Loss: 0.02130 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 013 | Batch: 300 | Loss: 0.02092 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 013 | Batch: 400 | Loss: 0.02015 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 013 | Batch: 000 | Loss: 0.01583 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 013 | Batch: 100 | Loss: 0.02621 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 013 | Batch: 200 | Loss: 0.03890 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 013 | Batch: 300 | Loss: 0.00680 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 013 | Batch: 400 | Loss: 0.02842 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 013 | Batch: 000 | Loss: 0.00890 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 013 | Batch: 100 | Loss: 0.00841 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 013 | Batch: 200 | Loss: 0.01417 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 013 | Batch: 300 | Loss: 0.01169 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 013 | Batch: 400 | Loss: 0.03694 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 013 | Batch: 000 | Loss: 0.04200 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 013 | Batch: 100 | Loss: 0.02051 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 013 | Batch: 200 | Loss: 0.02492 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 013 | Batch: 300 | Loss: 0.03623 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 013 | Batch: 400 | Loss: 0.03074 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 013 | Batch: 000 | Loss: 0.02267 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 013 | Batch: 100 | Loss: 0.01422 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 013 | Batch: 200 | Loss: 0.01910 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 013 | Batch: 300 | Loss: 0.05812 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 013 | Batch: 400 | Loss: 0.02939 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 013 | Batch: 000 | Loss: 0.03210 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 013 | Batch: 100 | Loss: 0.01863 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 013 | Batch: 200 | Loss: 0.06350 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 013 | Batch: 300 | Loss: 0.05137 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 013 | Batch: 400 | Loss: 0.02203 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 013 | Batch: 000 | Loss: 0.02414 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 013 | Batch: 100 | Loss: 0.01756 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 013 | Batch: 200 | Loss: 0.02807 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 013 | Batch: 300 | Loss: 0.09197 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 013 | Batch: 400 | Loss: 0.02565 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 013 | Batch: 000 | Loss: 0.03479 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 013 | Batch: 100 | Loss: 0.02896 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 013 | Batch: 200 | Loss: 0.02812 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 013 | Batch: 300 | Loss: 0.02801 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 013 | Batch: 400 | Loss: 0.00871 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 013 | Batch: 000 | Loss: 0.00919 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 013 | Batch: 100 | Loss: 0.02946 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 013 | Batch: 200 | Loss: 0.00994 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 013 | Batch: 300 | Loss: 0.03480 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 013 | Batch: 400 | Loss: 0.01084 | Correct: 128/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:33:04,551 - INFO: Epoch: 013 | Validation Acc: 98.400 % | Historical Best: 98.490 %\n",
      "2022-09-25 01:33:04,551 - INFO: Epoch: 013 | Validation Acc: 98.400 % | Historical Best: 98.490 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 014 | Batch: 000 | Loss: 0.02145 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 014 | Batch: 100 | Loss: 0.00729 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 014 | Batch: 200 | Loss: 0.03353 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 014 | Batch: 300 | Loss: 0.06534 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 014 | Batch: 400 | Loss: 0.04801 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 014 | Batch: 000 | Loss: 0.03321 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 014 | Batch: 100 | Loss: 0.00796 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 014 | Batch: 200 | Loss: 0.04759 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 014 | Batch: 300 | Loss: 0.01082 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 014 | Batch: 400 | Loss: 0.04031 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 014 | Batch: 000 | Loss: 0.01847 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 014 | Batch: 100 | Loss: 0.01955 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 014 | Batch: 200 | Loss: 0.04036 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 014 | Batch: 300 | Loss: 0.02186 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 014 | Batch: 400 | Loss: 0.02699 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 014 | Batch: 000 | Loss: 0.01943 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 014 | Batch: 100 | Loss: 0.03407 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 014 | Batch: 200 | Loss: 0.01207 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 014 | Batch: 300 | Loss: 0.03015 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 014 | Batch: 400 | Loss: 0.02844 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 014 | Batch: 000 | Loss: 0.01547 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 014 | Batch: 100 | Loss: 0.02533 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 014 | Batch: 200 | Loss: 0.02956 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 014 | Batch: 300 | Loss: 0.04246 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 014 | Batch: 400 | Loss: 0.01474 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 014 | Batch: 000 | Loss: 0.08557 | Correct: 123/128\n",
      "Estimator: 005 | Epoch: 014 | Batch: 100 | Loss: 0.01152 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 014 | Batch: 200 | Loss: 0.02214 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 014 | Batch: 300 | Loss: 0.02262 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 014 | Batch: 400 | Loss: 0.00559 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 014 | Batch: 000 | Loss: 0.04295 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 014 | Batch: 100 | Loss: 0.01962 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 014 | Batch: 200 | Loss: 0.02411 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 014 | Batch: 300 | Loss: 0.02634 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 014 | Batch: 400 | Loss: 0.00878 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 014 | Batch: 000 | Loss: 0.01053 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 014 | Batch: 100 | Loss: 0.03453 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 014 | Batch: 200 | Loss: 0.04605 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 014 | Batch: 300 | Loss: 0.05542 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 014 | Batch: 400 | Loss: 0.04707 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 014 | Batch: 000 | Loss: 0.01697 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 014 | Batch: 100 | Loss: 0.08598 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 014 | Batch: 200 | Loss: 0.00858 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 014 | Batch: 300 | Loss: 0.01856 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 014 | Batch: 400 | Loss: 0.06487 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 014 | Batch: 000 | Loss: 0.03569 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 014 | Batch: 100 | Loss: 0.03331 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 014 | Batch: 200 | Loss: 0.03256 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 014 | Batch: 300 | Loss: 0.00913 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 014 | Batch: 400 | Loss: 0.04370 | Correct: 125/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:34:43,943 - INFO: Epoch: 014 | Validation Acc: 98.450 % | Historical Best: 98.490 %\n",
      "2022-09-25 01:34:43,943 - INFO: Epoch: 014 | Validation Acc: 98.450 % | Historical Best: 98.490 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 015 | Batch: 000 | Loss: 0.00791 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 015 | Batch: 100 | Loss: 0.02411 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 015 | Batch: 200 | Loss: 0.01848 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 015 | Batch: 300 | Loss: 0.00856 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 015 | Batch: 400 | Loss: 0.03970 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 015 | Batch: 000 | Loss: 0.01406 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 015 | Batch: 100 | Loss: 0.03860 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 015 | Batch: 200 | Loss: 0.04316 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 015 | Batch: 300 | Loss: 0.03059 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 015 | Batch: 400 | Loss: 0.08109 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 015 | Batch: 000 | Loss: 0.04371 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 015 | Batch: 100 | Loss: 0.03602 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 015 | Batch: 200 | Loss: 0.01885 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 015 | Batch: 300 | Loss: 0.04522 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 015 | Batch: 400 | Loss: 0.00479 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 015 | Batch: 000 | Loss: 0.01680 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 015 | Batch: 100 | Loss: 0.01997 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 015 | Batch: 200 | Loss: 0.04214 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 015 | Batch: 300 | Loss: 0.01138 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 015 | Batch: 400 | Loss: 0.01198 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 015 | Batch: 000 | Loss: 0.01879 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 015 | Batch: 100 | Loss: 0.02433 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 015 | Batch: 200 | Loss: 0.01695 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 015 | Batch: 300 | Loss: 0.01192 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 015 | Batch: 400 | Loss: 0.01813 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 015 | Batch: 000 | Loss: 0.02467 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 015 | Batch: 100 | Loss: 0.00778 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 015 | Batch: 200 | Loss: 0.04666 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 015 | Batch: 300 | Loss: 0.04273 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 015 | Batch: 400 | Loss: 0.02403 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 015 | Batch: 000 | Loss: 0.05572 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 015 | Batch: 100 | Loss: 0.01297 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 015 | Batch: 200 | Loss: 0.04224 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 015 | Batch: 300 | Loss: 0.02917 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 015 | Batch: 400 | Loss: 0.03898 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 015 | Batch: 000 | Loss: 0.02907 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 015 | Batch: 100 | Loss: 0.02196 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 015 | Batch: 200 | Loss: 0.05397 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 015 | Batch: 300 | Loss: 0.01874 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 015 | Batch: 400 | Loss: 0.04267 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 015 | Batch: 000 | Loss: 0.01022 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 015 | Batch: 100 | Loss: 0.01184 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 015 | Batch: 200 | Loss: 0.03932 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 015 | Batch: 300 | Loss: 0.04157 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 015 | Batch: 400 | Loss: 0.01321 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 015 | Batch: 000 | Loss: 0.06601 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 015 | Batch: 100 | Loss: 0.04089 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 015 | Batch: 200 | Loss: 0.08266 | Correct: 121/128\n",
      "Estimator: 009 | Epoch: 015 | Batch: 300 | Loss: 0.04831 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 015 | Batch: 400 | Loss: 0.04710 | Correct: 126/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:36:22,462 - INFO: Epoch: 015 | Validation Acc: 98.490 % | Historical Best: 98.490 %\n",
      "2022-09-25 01:36:22,462 - INFO: Epoch: 015 | Validation Acc: 98.490 % | Historical Best: 98.490 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 016 | Batch: 000 | Loss: 0.03977 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 016 | Batch: 100 | Loss: 0.04069 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 016 | Batch: 200 | Loss: 0.06899 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 016 | Batch: 300 | Loss: 0.00935 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 016 | Batch: 400 | Loss: 0.02389 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 016 | Batch: 000 | Loss: 0.01293 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 016 | Batch: 100 | Loss: 0.01425 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 016 | Batch: 200 | Loss: 0.02338 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 016 | Batch: 300 | Loss: 0.06746 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 016 | Batch: 400 | Loss: 0.03242 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 016 | Batch: 000 | Loss: 0.04433 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 016 | Batch: 100 | Loss: 0.01578 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 016 | Batch: 200 | Loss: 0.01968 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 016 | Batch: 300 | Loss: 0.04292 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 016 | Batch: 400 | Loss: 0.04440 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 016 | Batch: 000 | Loss: 0.01189 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 016 | Batch: 100 | Loss: 0.01485 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 016 | Batch: 200 | Loss: 0.04094 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 016 | Batch: 300 | Loss: 0.02191 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 016 | Batch: 400 | Loss: 0.02748 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 016 | Batch: 000 | Loss: 0.01289 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 016 | Batch: 100 | Loss: 0.02399 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 016 | Batch: 200 | Loss: 0.01988 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 016 | Batch: 300 | Loss: 0.01681 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 016 | Batch: 400 | Loss: 0.03798 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 016 | Batch: 000 | Loss: 0.01680 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 016 | Batch: 100 | Loss: 0.04332 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 016 | Batch: 200 | Loss: 0.06163 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 016 | Batch: 300 | Loss: 0.02919 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 016 | Batch: 400 | Loss: 0.04246 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 016 | Batch: 000 | Loss: 0.01165 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 016 | Batch: 100 | Loss: 0.01639 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 016 | Batch: 200 | Loss: 0.02813 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 016 | Batch: 300 | Loss: 0.03045 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 016 | Batch: 400 | Loss: 0.03104 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 016 | Batch: 000 | Loss: 0.02730 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 016 | Batch: 100 | Loss: 0.00752 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 016 | Batch: 200 | Loss: 0.00595 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 016 | Batch: 300 | Loss: 0.04504 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 016 | Batch: 400 | Loss: 0.02392 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 016 | Batch: 000 | Loss: 0.03116 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 016 | Batch: 100 | Loss: 0.00512 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 016 | Batch: 200 | Loss: 0.02374 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 016 | Batch: 300 | Loss: 0.01393 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 016 | Batch: 400 | Loss: 0.08245 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 016 | Batch: 000 | Loss: 0.09200 | Correct: 123/128\n",
      "Estimator: 009 | Epoch: 016 | Batch: 100 | Loss: 0.12027 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 016 | Batch: 200 | Loss: 0.03530 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 016 | Batch: 300 | Loss: 0.04045 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 016 | Batch: 400 | Loss: 0.00564 | Correct: 128/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:38:01,787 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:38:01,787 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:38:01,906 - INFO: Epoch: 016 | Validation Acc: 98.530 % | Historical Best: 98.530 %\n",
      "2022-09-25 01:38:01,906 - INFO: Epoch: 016 | Validation Acc: 98.530 % | Historical Best: 98.530 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 017 | Batch: 000 | Loss: 0.07282 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 017 | Batch: 100 | Loss: 0.02094 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 017 | Batch: 200 | Loss: 0.01480 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 017 | Batch: 300 | Loss: 0.00331 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 017 | Batch: 400 | Loss: 0.06328 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 017 | Batch: 000 | Loss: 0.02517 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 017 | Batch: 100 | Loss: 0.04795 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 017 | Batch: 200 | Loss: 0.03258 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 017 | Batch: 300 | Loss: 0.02787 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 017 | Batch: 400 | Loss: 0.02582 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 017 | Batch: 000 | Loss: 0.00636 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 017 | Batch: 100 | Loss: 0.01731 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 017 | Batch: 200 | Loss: 0.01031 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 017 | Batch: 300 | Loss: 0.03539 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 017 | Batch: 400 | Loss: 0.00327 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 017 | Batch: 000 | Loss: 0.00793 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 017 | Batch: 100 | Loss: 0.01688 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 017 | Batch: 200 | Loss: 0.02061 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 017 | Batch: 300 | Loss: 0.03448 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 017 | Batch: 400 | Loss: 0.02189 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 017 | Batch: 000 | Loss: 0.04724 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 017 | Batch: 100 | Loss: 0.02371 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 017 | Batch: 200 | Loss: 0.04938 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 017 | Batch: 300 | Loss: 0.02480 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 017 | Batch: 400 | Loss: 0.05610 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 017 | Batch: 000 | Loss: 0.00846 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 017 | Batch: 100 | Loss: 0.02463 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 017 | Batch: 200 | Loss: 0.02195 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 017 | Batch: 300 | Loss: 0.01486 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 017 | Batch: 400 | Loss: 0.01447 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 017 | Batch: 000 | Loss: 0.05138 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 017 | Batch: 100 | Loss: 0.01784 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 017 | Batch: 200 | Loss: 0.02100 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 017 | Batch: 300 | Loss: 0.06335 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 017 | Batch: 400 | Loss: 0.01067 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 017 | Batch: 000 | Loss: 0.05823 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 017 | Batch: 100 | Loss: 0.00753 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 017 | Batch: 200 | Loss: 0.02829 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 017 | Batch: 300 | Loss: 0.02339 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 017 | Batch: 400 | Loss: 0.04823 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 017 | Batch: 000 | Loss: 0.01037 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 017 | Batch: 100 | Loss: 0.01954 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 017 | Batch: 200 | Loss: 0.06116 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 017 | Batch: 300 | Loss: 0.01127 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 017 | Batch: 400 | Loss: 0.01544 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 017 | Batch: 000 | Loss: 0.02063 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 017 | Batch: 100 | Loss: 0.00931 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 017 | Batch: 200 | Loss: 0.02586 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 017 | Batch: 300 | Loss: 0.04348 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 017 | Batch: 400 | Loss: 0.00566 | Correct: 128/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:39:41,768 - INFO: Epoch: 017 | Validation Acc: 98.460 % | Historical Best: 98.530 %\n",
      "2022-09-25 01:39:41,768 - INFO: Epoch: 017 | Validation Acc: 98.460 % | Historical Best: 98.530 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 018 | Batch: 000 | Loss: 0.03422 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 018 | Batch: 100 | Loss: 0.01167 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 018 | Batch: 200 | Loss: 0.02705 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 018 | Batch: 300 | Loss: 0.03126 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 018 | Batch: 400 | Loss: 0.01161 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 018 | Batch: 000 | Loss: 0.01436 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 018 | Batch: 100 | Loss: 0.02000 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 018 | Batch: 200 | Loss: 0.01267 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 018 | Batch: 300 | Loss: 0.02735 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 018 | Batch: 400 | Loss: 0.03977 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 018 | Batch: 000 | Loss: 0.00707 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 018 | Batch: 100 | Loss: 0.01442 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 018 | Batch: 200 | Loss: 0.05012 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 018 | Batch: 300 | Loss: 0.06964 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 018 | Batch: 400 | Loss: 0.00777 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 018 | Batch: 000 | Loss: 0.01102 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 018 | Batch: 100 | Loss: 0.02001 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 018 | Batch: 200 | Loss: 0.01642 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 018 | Batch: 300 | Loss: 0.03149 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 018 | Batch: 400 | Loss: 0.02111 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 018 | Batch: 000 | Loss: 0.03718 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 018 | Batch: 100 | Loss: 0.02141 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 018 | Batch: 200 | Loss: 0.06608 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 018 | Batch: 300 | Loss: 0.04533 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 018 | Batch: 400 | Loss: 0.02681 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 018 | Batch: 000 | Loss: 0.02379 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 018 | Batch: 100 | Loss: 0.02848 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 018 | Batch: 200 | Loss: 0.03786 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 018 | Batch: 300 | Loss: 0.04106 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 018 | Batch: 400 | Loss: 0.03482 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 018 | Batch: 000 | Loss: 0.01763 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 018 | Batch: 100 | Loss: 0.02270 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 018 | Batch: 200 | Loss: 0.01587 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 018 | Batch: 300 | Loss: 0.02389 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 018 | Batch: 400 | Loss: 0.03712 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 018 | Batch: 000 | Loss: 0.01531 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 018 | Batch: 100 | Loss: 0.03480 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 018 | Batch: 200 | Loss: 0.00710 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 018 | Batch: 300 | Loss: 0.01567 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 018 | Batch: 400 | Loss: 0.01123 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 018 | Batch: 000 | Loss: 0.01522 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 018 | Batch: 100 | Loss: 0.03126 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 018 | Batch: 200 | Loss: 0.00858 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 018 | Batch: 300 | Loss: 0.02380 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 018 | Batch: 400 | Loss: 0.01695 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 018 | Batch: 000 | Loss: 0.01353 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 018 | Batch: 100 | Loss: 0.00867 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 018 | Batch: 200 | Loss: 0.01307 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 018 | Batch: 300 | Loss: 0.09235 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 018 | Batch: 400 | Loss: 0.05287 | Correct: 125/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:41:21,637 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:41:21,637 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:41:21,650 - INFO: Epoch: 018 | Validation Acc: 98.550 % | Historical Best: 98.550 %\n",
      "2022-09-25 01:41:21,650 - INFO: Epoch: 018 | Validation Acc: 98.550 % | Historical Best: 98.550 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 019 | Batch: 000 | Loss: 0.02248 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 019 | Batch: 100 | Loss: 0.01440 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 019 | Batch: 200 | Loss: 0.03721 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 019 | Batch: 300 | Loss: 0.01413 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 019 | Batch: 400 | Loss: 0.03676 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 019 | Batch: 000 | Loss: 0.08305 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 019 | Batch: 100 | Loss: 0.02186 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 019 | Batch: 200 | Loss: 0.02493 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 019 | Batch: 300 | Loss: 0.05602 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 019 | Batch: 400 | Loss: 0.03232 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 019 | Batch: 000 | Loss: 0.01036 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 019 | Batch: 100 | Loss: 0.01932 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 019 | Batch: 200 | Loss: 0.02753 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 019 | Batch: 300 | Loss: 0.03375 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 019 | Batch: 400 | Loss: 0.02721 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 019 | Batch: 000 | Loss: 0.01885 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 019 | Batch: 100 | Loss: 0.01307 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 019 | Batch: 200 | Loss: 0.04562 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 019 | Batch: 300 | Loss: 0.01057 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 019 | Batch: 400 | Loss: 0.02919 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 019 | Batch: 000 | Loss: 0.01991 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 019 | Batch: 100 | Loss: 0.00693 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 019 | Batch: 200 | Loss: 0.01034 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 019 | Batch: 300 | Loss: 0.03815 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 019 | Batch: 400 | Loss: 0.03343 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 019 | Batch: 000 | Loss: 0.06984 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 019 | Batch: 100 | Loss: 0.04610 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 019 | Batch: 200 | Loss: 0.00997 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 019 | Batch: 300 | Loss: 0.05385 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 019 | Batch: 400 | Loss: 0.00820 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 019 | Batch: 000 | Loss: 0.01642 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 019 | Batch: 100 | Loss: 0.06337 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 019 | Batch: 200 | Loss: 0.05068 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 019 | Batch: 300 | Loss: 0.03567 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 019 | Batch: 400 | Loss: 0.02913 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 019 | Batch: 000 | Loss: 0.00616 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 019 | Batch: 100 | Loss: 0.02177 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 019 | Batch: 200 | Loss: 0.01533 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 019 | Batch: 300 | Loss: 0.03983 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 019 | Batch: 400 | Loss: 0.01351 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 019 | Batch: 000 | Loss: 0.02737 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 019 | Batch: 100 | Loss: 0.01331 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 019 | Batch: 200 | Loss: 0.00806 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 019 | Batch: 300 | Loss: 0.01519 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 019 | Batch: 400 | Loss: 0.01480 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 019 | Batch: 000 | Loss: 0.00974 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 019 | Batch: 100 | Loss: 0.01387 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 019 | Batch: 200 | Loss: 0.01423 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 019 | Batch: 300 | Loss: 0.00721 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 019 | Batch: 400 | Loss: 0.01844 | Correct: 128/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:43:00,266 - INFO: Epoch: 019 | Validation Acc: 98.520 % | Historical Best: 98.550 %\n",
      "2022-09-25 01:43:00,266 - INFO: Epoch: 019 | Validation Acc: 98.520 % | Historical Best: 98.550 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 020 | Batch: 000 | Loss: 0.03207 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 020 | Batch: 100 | Loss: 0.02342 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 020 | Batch: 200 | Loss: 0.01071 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 020 | Batch: 300 | Loss: 0.04580 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 020 | Batch: 400 | Loss: 0.02811 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 020 | Batch: 000 | Loss: 0.01678 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 020 | Batch: 100 | Loss: 0.01149 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 020 | Batch: 200 | Loss: 0.05767 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 020 | Batch: 300 | Loss: 0.01340 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 020 | Batch: 400 | Loss: 0.02646 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 020 | Batch: 000 | Loss: 0.01337 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 020 | Batch: 100 | Loss: 0.00998 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 020 | Batch: 200 | Loss: 0.04217 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 020 | Batch: 300 | Loss: 0.02062 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 020 | Batch: 400 | Loss: 0.01634 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 020 | Batch: 000 | Loss: 0.01919 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 020 | Batch: 100 | Loss: 0.07798 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 020 | Batch: 200 | Loss: 0.00708 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 020 | Batch: 300 | Loss: 0.01364 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 020 | Batch: 400 | Loss: 0.00962 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 020 | Batch: 000 | Loss: 0.02794 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 020 | Batch: 100 | Loss: 0.01118 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 020 | Batch: 200 | Loss: 0.03410 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 020 | Batch: 300 | Loss: 0.03033 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 020 | Batch: 400 | Loss: 0.03831 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 020 | Batch: 000 | Loss: 0.02549 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 020 | Batch: 100 | Loss: 0.01609 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 020 | Batch: 200 | Loss: 0.02121 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 020 | Batch: 300 | Loss: 0.04806 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 020 | Batch: 400 | Loss: 0.05293 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 020 | Batch: 000 | Loss: 0.02993 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 020 | Batch: 100 | Loss: 0.01143 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 020 | Batch: 200 | Loss: 0.02645 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 020 | Batch: 300 | Loss: 0.10364 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 020 | Batch: 400 | Loss: 0.04523 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 020 | Batch: 000 | Loss: 0.00764 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 020 | Batch: 100 | Loss: 0.00800 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 020 | Batch: 200 | Loss: 0.03124 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 020 | Batch: 300 | Loss: 0.02663 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 020 | Batch: 400 | Loss: 0.04945 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 020 | Batch: 000 | Loss: 0.00483 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 020 | Batch: 100 | Loss: 0.05309 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 020 | Batch: 200 | Loss: 0.02733 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 020 | Batch: 300 | Loss: 0.01690 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 020 | Batch: 400 | Loss: 0.00899 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 020 | Batch: 000 | Loss: 0.03298 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 020 | Batch: 100 | Loss: 0.03043 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 020 | Batch: 200 | Loss: 0.03518 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 020 | Batch: 300 | Loss: 0.02040 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 020 | Batch: 400 | Loss: 0.01476 | Correct: 128/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:44:39,652 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:44:39,652 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:44:39,770 - INFO: Epoch: 020 | Validation Acc: 98.570 % | Historical Best: 98.570 %\n",
      "2022-09-25 01:44:39,770 - INFO: Epoch: 020 | Validation Acc: 98.570 % | Historical Best: 98.570 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 021 | Batch: 000 | Loss: 0.06755 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 021 | Batch: 100 | Loss: 0.00927 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 021 | Batch: 200 | Loss: 0.00771 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 021 | Batch: 300 | Loss: 0.00644 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 021 | Batch: 400 | Loss: 0.01469 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 021 | Batch: 000 | Loss: 0.06434 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 021 | Batch: 100 | Loss: 0.00656 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 021 | Batch: 200 | Loss: 0.04338 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 021 | Batch: 300 | Loss: 0.02422 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 021 | Batch: 400 | Loss: 0.01346 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 021 | Batch: 000 | Loss: 0.01334 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 021 | Batch: 100 | Loss: 0.00694 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 021 | Batch: 200 | Loss: 0.05813 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 021 | Batch: 300 | Loss: 0.02490 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 021 | Batch: 400 | Loss: 0.00987 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 021 | Batch: 000 | Loss: 0.00801 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 021 | Batch: 100 | Loss: 0.00279 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 021 | Batch: 200 | Loss: 0.02426 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 021 | Batch: 300 | Loss: 0.01934 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 021 | Batch: 400 | Loss: 0.10514 | Correct: 121/128\n",
      "Estimator: 004 | Epoch: 021 | Batch: 000 | Loss: 0.01460 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 021 | Batch: 100 | Loss: 0.01564 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 021 | Batch: 200 | Loss: 0.01728 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 021 | Batch: 300 | Loss: 0.04356 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 021 | Batch: 400 | Loss: 0.02217 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 021 | Batch: 000 | Loss: 0.02760 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 021 | Batch: 100 | Loss: 0.01815 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 021 | Batch: 200 | Loss: 0.01299 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 021 | Batch: 300 | Loss: 0.02993 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 021 | Batch: 400 | Loss: 0.01875 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 021 | Batch: 000 | Loss: 0.01014 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 021 | Batch: 100 | Loss: 0.00793 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 021 | Batch: 200 | Loss: 0.01481 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 021 | Batch: 300 | Loss: 0.01041 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 021 | Batch: 400 | Loss: 0.07731 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 021 | Batch: 000 | Loss: 0.01377 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 021 | Batch: 100 | Loss: 0.05650 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 021 | Batch: 200 | Loss: 0.00676 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 021 | Batch: 300 | Loss: 0.00954 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 021 | Batch: 400 | Loss: 0.02352 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 021 | Batch: 000 | Loss: 0.04175 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 021 | Batch: 100 | Loss: 0.06670 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 021 | Batch: 200 | Loss: 0.01485 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 021 | Batch: 300 | Loss: 0.03173 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 021 | Batch: 400 | Loss: 0.01111 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 021 | Batch: 000 | Loss: 0.01818 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 021 | Batch: 100 | Loss: 0.01374 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 021 | Batch: 200 | Loss: 0.02032 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 021 | Batch: 300 | Loss: 0.00968 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 021 | Batch: 400 | Loss: 0.04463 | Correct: 126/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:46:19,009 - INFO: Epoch: 021 | Validation Acc: 98.560 % | Historical Best: 98.570 %\n",
      "2022-09-25 01:46:19,009 - INFO: Epoch: 021 | Validation Acc: 98.560 % | Historical Best: 98.570 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 022 | Batch: 000 | Loss: 0.01327 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 022 | Batch: 100 | Loss: 0.02487 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 022 | Batch: 200 | Loss: 0.02910 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 022 | Batch: 300 | Loss: 0.01615 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 022 | Batch: 400 | Loss: 0.01729 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 022 | Batch: 000 | Loss: 0.00707 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 022 | Batch: 100 | Loss: 0.03528 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 022 | Batch: 200 | Loss: 0.00889 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 022 | Batch: 300 | Loss: 0.07723 | Correct: 123/128\n",
      "Estimator: 001 | Epoch: 022 | Batch: 400 | Loss: 0.03135 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 022 | Batch: 000 | Loss: 0.03848 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 022 | Batch: 100 | Loss: 0.01125 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 022 | Batch: 200 | Loss: 0.02047 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 022 | Batch: 300 | Loss: 0.01258 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 022 | Batch: 400 | Loss: 0.01951 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 022 | Batch: 000 | Loss: 0.03100 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 022 | Batch: 100 | Loss: 0.01212 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 022 | Batch: 200 | Loss: 0.01796 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 022 | Batch: 300 | Loss: 0.01691 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 022 | Batch: 400 | Loss: 0.02579 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 022 | Batch: 000 | Loss: 0.03245 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 022 | Batch: 100 | Loss: 0.02125 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 022 | Batch: 200 | Loss: 0.02026 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 022 | Batch: 300 | Loss: 0.03803 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 022 | Batch: 400 | Loss: 0.00864 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 022 | Batch: 000 | Loss: 0.01946 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 022 | Batch: 100 | Loss: 0.00665 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 022 | Batch: 200 | Loss: 0.03926 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 022 | Batch: 300 | Loss: 0.01687 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 022 | Batch: 400 | Loss: 0.01865 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 022 | Batch: 000 | Loss: 0.00388 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 022 | Batch: 100 | Loss: 0.02069 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 022 | Batch: 200 | Loss: 0.00685 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 022 | Batch: 300 | Loss: 0.01115 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 022 | Batch: 400 | Loss: 0.02286 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 022 | Batch: 000 | Loss: 0.01403 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 022 | Batch: 100 | Loss: 0.01005 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 022 | Batch: 200 | Loss: 0.03222 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 022 | Batch: 300 | Loss: 0.03566 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 022 | Batch: 400 | Loss: 0.02263 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 022 | Batch: 000 | Loss: 0.01213 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 022 | Batch: 100 | Loss: 0.00545 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 022 | Batch: 200 | Loss: 0.03555 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 022 | Batch: 300 | Loss: 0.06715 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 022 | Batch: 400 | Loss: 0.00715 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 022 | Batch: 000 | Loss: 0.02663 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 022 | Batch: 100 | Loss: 0.03725 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 022 | Batch: 200 | Loss: 0.00552 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 022 | Batch: 300 | Loss: 0.03071 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 022 | Batch: 400 | Loss: 0.04143 | Correct: 124/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:47:57,704 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:47:57,704 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 01:47:57,820 - INFO: Epoch: 022 | Validation Acc: 98.650 % | Historical Best: 98.650 %\n",
      "2022-09-25 01:47:57,820 - INFO: Epoch: 022 | Validation Acc: 98.650 % | Historical Best: 98.650 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 023 | Batch: 000 | Loss: 0.01295 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 023 | Batch: 100 | Loss: 0.01290 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 023 | Batch: 200 | Loss: 0.01915 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 023 | Batch: 300 | Loss: 0.04467 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 023 | Batch: 400 | Loss: 0.00491 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 023 | Batch: 000 | Loss: 0.05649 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 023 | Batch: 100 | Loss: 0.01273 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 023 | Batch: 200 | Loss: 0.02357 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 023 | Batch: 300 | Loss: 0.01354 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 023 | Batch: 400 | Loss: 0.03681 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 023 | Batch: 000 | Loss: 0.03961 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 023 | Batch: 100 | Loss: 0.03540 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 023 | Batch: 200 | Loss: 0.01685 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 023 | Batch: 300 | Loss: 0.01304 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 023 | Batch: 400 | Loss: 0.02546 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 023 | Batch: 000 | Loss: 0.00995 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 023 | Batch: 100 | Loss: 0.03614 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 023 | Batch: 200 | Loss: 0.01371 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 023 | Batch: 300 | Loss: 0.03741 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 023 | Batch: 400 | Loss: 0.04854 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 023 | Batch: 000 | Loss: 0.01950 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 023 | Batch: 100 | Loss: 0.02296 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 023 | Batch: 200 | Loss: 0.02651 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 023 | Batch: 300 | Loss: 0.00854 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 023 | Batch: 400 | Loss: 0.00597 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 023 | Batch: 000 | Loss: 0.02221 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 023 | Batch: 100 | Loss: 0.04041 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 023 | Batch: 200 | Loss: 0.02956 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 023 | Batch: 300 | Loss: 0.04056 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 023 | Batch: 400 | Loss: 0.01495 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 023 | Batch: 000 | Loss: 0.02883 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 023 | Batch: 100 | Loss: 0.00658 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 023 | Batch: 200 | Loss: 0.01654 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 023 | Batch: 300 | Loss: 0.04624 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 023 | Batch: 400 | Loss: 0.00694 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 023 | Batch: 000 | Loss: 0.00825 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 023 | Batch: 100 | Loss: 0.00653 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 023 | Batch: 200 | Loss: 0.00528 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 023 | Batch: 300 | Loss: 0.03279 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 023 | Batch: 400 | Loss: 0.01760 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 023 | Batch: 000 | Loss: 0.01932 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 023 | Batch: 100 | Loss: 0.02559 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 023 | Batch: 200 | Loss: 0.01424 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 023 | Batch: 300 | Loss: 0.01652 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 023 | Batch: 400 | Loss: 0.01639 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 023 | Batch: 000 | Loss: 0.01466 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 023 | Batch: 100 | Loss: 0.00590 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 023 | Batch: 200 | Loss: 0.00603 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 023 | Batch: 300 | Loss: 0.03844 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 023 | Batch: 400 | Loss: 0.02438 | Correct: 127/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:49:36,955 - INFO: Epoch: 023 | Validation Acc: 98.600 % | Historical Best: 98.650 %\n",
      "2022-09-25 01:49:36,955 - INFO: Epoch: 023 | Validation Acc: 98.600 % | Historical Best: 98.650 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 024 | Batch: 000 | Loss: 0.00502 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 024 | Batch: 100 | Loss: 0.01314 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 024 | Batch: 200 | Loss: 0.02549 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 024 | Batch: 300 | Loss: 0.03044 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 024 | Batch: 400 | Loss: 0.01547 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 024 | Batch: 000 | Loss: 0.00414 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 024 | Batch: 100 | Loss: 0.01547 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 024 | Batch: 200 | Loss: 0.01701 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 024 | Batch: 300 | Loss: 0.01716 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 024 | Batch: 400 | Loss: 0.03131 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 024 | Batch: 000 | Loss: 0.02630 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 024 | Batch: 100 | Loss: 0.00277 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 024 | Batch: 200 | Loss: 0.00589 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 024 | Batch: 300 | Loss: 0.02822 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 024 | Batch: 400 | Loss: 0.00719 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 024 | Batch: 000 | Loss: 0.03316 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 024 | Batch: 100 | Loss: 0.01455 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 024 | Batch: 200 | Loss: 0.00375 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 024 | Batch: 300 | Loss: 0.01495 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 024 | Batch: 400 | Loss: 0.03964 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 024 | Batch: 000 | Loss: 0.01938 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 024 | Batch: 100 | Loss: 0.03605 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 024 | Batch: 200 | Loss: 0.06864 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 024 | Batch: 300 | Loss: 0.01296 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 024 | Batch: 400 | Loss: 0.01136 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 024 | Batch: 000 | Loss: 0.00742 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 024 | Batch: 100 | Loss: 0.02807 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 024 | Batch: 200 | Loss: 0.01711 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 024 | Batch: 300 | Loss: 0.02391 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 024 | Batch: 400 | Loss: 0.02008 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 024 | Batch: 000 | Loss: 0.01035 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 024 | Batch: 100 | Loss: 0.00757 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 024 | Batch: 200 | Loss: 0.05290 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 024 | Batch: 300 | Loss: 0.01664 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 024 | Batch: 400 | Loss: 0.04763 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 024 | Batch: 000 | Loss: 0.00514 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 024 | Batch: 100 | Loss: 0.01806 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 024 | Batch: 200 | Loss: 0.05184 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 024 | Batch: 300 | Loss: 0.01181 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 024 | Batch: 400 | Loss: 0.01926 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 024 | Batch: 000 | Loss: 0.03174 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 024 | Batch: 100 | Loss: 0.01017 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 024 | Batch: 200 | Loss: 0.02889 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 024 | Batch: 300 | Loss: 0.02286 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 024 | Batch: 400 | Loss: 0.02086 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 024 | Batch: 000 | Loss: 0.01104 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 024 | Batch: 100 | Loss: 0.02735 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 024 | Batch: 200 | Loss: 0.00585 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 024 | Batch: 300 | Loss: 0.00996 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 024 | Batch: 400 | Loss: 0.03225 | Correct: 126/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:51:15,837 - INFO: Epoch: 024 | Validation Acc: 98.590 % | Historical Best: 98.650 %\n",
      "2022-09-25 01:51:15,837 - INFO: Epoch: 024 | Validation Acc: 98.590 % | Historical Best: 98.650 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 025 | Batch: 000 | Loss: 0.01042 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 025 | Batch: 100 | Loss: 0.00786 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 025 | Batch: 200 | Loss: 0.02615 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 025 | Batch: 300 | Loss: 0.01387 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 025 | Batch: 400 | Loss: 0.02398 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 025 | Batch: 000 | Loss: 0.03104 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 025 | Batch: 100 | Loss: 0.01524 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 025 | Batch: 200 | Loss: 0.03663 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 025 | Batch: 300 | Loss: 0.06044 | Correct: 124/128\n",
      "Estimator: 001 | Epoch: 025 | Batch: 400 | Loss: 0.02023 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 025 | Batch: 000 | Loss: 0.01869 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 025 | Batch: 100 | Loss: 0.05627 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 025 | Batch: 200 | Loss: 0.00697 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 025 | Batch: 300 | Loss: 0.00871 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 025 | Batch: 400 | Loss: 0.02893 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 025 | Batch: 000 | Loss: 0.05700 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 025 | Batch: 100 | Loss: 0.00284 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 025 | Batch: 200 | Loss: 0.00615 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 025 | Batch: 300 | Loss: 0.01033 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 025 | Batch: 400 | Loss: 0.01279 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 025 | Batch: 000 | Loss: 0.00663 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 025 | Batch: 100 | Loss: 0.01526 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 025 | Batch: 200 | Loss: 0.04578 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 025 | Batch: 300 | Loss: 0.01062 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 025 | Batch: 400 | Loss: 0.02164 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 025 | Batch: 000 | Loss: 0.04252 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 025 | Batch: 100 | Loss: 0.00762 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 025 | Batch: 200 | Loss: 0.01081 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 025 | Batch: 300 | Loss: 0.06749 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 025 | Batch: 400 | Loss: 0.00523 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 025 | Batch: 000 | Loss: 0.04940 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 025 | Batch: 100 | Loss: 0.06741 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 025 | Batch: 200 | Loss: 0.03710 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 025 | Batch: 300 | Loss: 0.03973 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 025 | Batch: 400 | Loss: 0.03921 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 025 | Batch: 000 | Loss: 0.00674 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 025 | Batch: 100 | Loss: 0.01635 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 025 | Batch: 200 | Loss: 0.00764 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 025 | Batch: 300 | Loss: 0.01785 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 025 | Batch: 400 | Loss: 0.02198 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 025 | Batch: 000 | Loss: 0.01956 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 025 | Batch: 100 | Loss: 0.01636 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 025 | Batch: 200 | Loss: 0.01041 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 025 | Batch: 300 | Loss: 0.03187 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 025 | Batch: 400 | Loss: 0.01971 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 025 | Batch: 000 | Loss: 0.01482 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 025 | Batch: 100 | Loss: 0.01397 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 025 | Batch: 200 | Loss: 0.01625 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 025 | Batch: 300 | Loss: 0.03088 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 025 | Batch: 400 | Loss: 0.00548 | Correct: 128/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:52:54,740 - INFO: Epoch: 025 | Validation Acc: 98.490 % | Historical Best: 98.650 %\n",
      "2022-09-25 01:52:54,740 - INFO: Epoch: 025 | Validation Acc: 98.490 % | Historical Best: 98.650 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 026 | Batch: 000 | Loss: 0.02660 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 026 | Batch: 100 | Loss: 0.03614 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 026 | Batch: 200 | Loss: 0.00850 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 026 | Batch: 300 | Loss: 0.04234 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 026 | Batch: 400 | Loss: 0.02382 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 026 | Batch: 000 | Loss: 0.02490 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 026 | Batch: 100 | Loss: 0.03386 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 026 | Batch: 200 | Loss: 0.01201 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 026 | Batch: 300 | Loss: 0.01422 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 026 | Batch: 400 | Loss: 0.01457 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 026 | Batch: 000 | Loss: 0.00923 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 026 | Batch: 100 | Loss: 0.01698 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 026 | Batch: 200 | Loss: 0.03544 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 026 | Batch: 300 | Loss: 0.02031 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 026 | Batch: 400 | Loss: 0.02103 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 026 | Batch: 000 | Loss: 0.03115 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 026 | Batch: 100 | Loss: 0.02067 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 026 | Batch: 200 | Loss: 0.00661 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 026 | Batch: 300 | Loss: 0.02743 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 026 | Batch: 400 | Loss: 0.03614 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 026 | Batch: 000 | Loss: 0.01168 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 026 | Batch: 100 | Loss: 0.00478 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 026 | Batch: 200 | Loss: 0.00500 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 026 | Batch: 300 | Loss: 0.01079 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 026 | Batch: 400 | Loss: 0.01089 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 026 | Batch: 000 | Loss: 0.03500 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 026 | Batch: 100 | Loss: 0.02500 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 026 | Batch: 200 | Loss: 0.02629 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 026 | Batch: 300 | Loss: 0.00508 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 026 | Batch: 400 | Loss: 0.03144 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 026 | Batch: 000 | Loss: 0.04272 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 026 | Batch: 100 | Loss: 0.01164 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 026 | Batch: 200 | Loss: 0.03194 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 026 | Batch: 300 | Loss: 0.00764 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 026 | Batch: 400 | Loss: 0.00743 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 026 | Batch: 000 | Loss: 0.00862 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 026 | Batch: 100 | Loss: 0.03098 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 026 | Batch: 200 | Loss: 0.01231 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 026 | Batch: 300 | Loss: 0.06418 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 026 | Batch: 400 | Loss: 0.02421 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 026 | Batch: 000 | Loss: 0.01064 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 026 | Batch: 100 | Loss: 0.01888 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 026 | Batch: 200 | Loss: 0.03204 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 026 | Batch: 300 | Loss: 0.00600 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 026 | Batch: 400 | Loss: 0.01142 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 026 | Batch: 000 | Loss: 0.01055 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 026 | Batch: 100 | Loss: 0.04028 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 026 | Batch: 200 | Loss: 0.05197 | Correct: 124/128\n",
      "Estimator: 009 | Epoch: 026 | Batch: 300 | Loss: 0.00821 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 026 | Batch: 400 | Loss: 0.08508 | Correct: 123/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:54:33,154 - INFO: Epoch: 026 | Validation Acc: 98.560 % | Historical Best: 98.650 %\n",
      "2022-09-25 01:54:33,154 - INFO: Epoch: 026 | Validation Acc: 98.560 % | Historical Best: 98.650 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 027 | Batch: 000 | Loss: 0.03849 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 027 | Batch: 100 | Loss: 0.01729 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 027 | Batch: 200 | Loss: 0.04160 | Correct: 124/128\n",
      "Estimator: 000 | Epoch: 027 | Batch: 300 | Loss: 0.02556 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 027 | Batch: 400 | Loss: 0.01799 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 027 | Batch: 000 | Loss: 0.00684 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 027 | Batch: 100 | Loss: 0.03820 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 027 | Batch: 200 | Loss: 0.01268 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 027 | Batch: 300 | Loss: 0.05495 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 027 | Batch: 400 | Loss: 0.05065 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 027 | Batch: 000 | Loss: 0.01419 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 027 | Batch: 100 | Loss: 0.01250 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 027 | Batch: 200 | Loss: 0.03143 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 027 | Batch: 300 | Loss: 0.03588 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 027 | Batch: 400 | Loss: 0.03237 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 027 | Batch: 000 | Loss: 0.00966 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 027 | Batch: 100 | Loss: 0.01021 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 027 | Batch: 200 | Loss: 0.02846 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 027 | Batch: 300 | Loss: 0.01035 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 027 | Batch: 400 | Loss: 0.02864 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 027 | Batch: 000 | Loss: 0.04267 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 027 | Batch: 100 | Loss: 0.01733 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 027 | Batch: 200 | Loss: 0.01701 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 027 | Batch: 300 | Loss: 0.01625 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 027 | Batch: 400 | Loss: 0.03643 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 027 | Batch: 000 | Loss: 0.01092 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 027 | Batch: 100 | Loss: 0.02271 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 027 | Batch: 200 | Loss: 0.01431 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 027 | Batch: 300 | Loss: 0.01830 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 027 | Batch: 400 | Loss: 0.03467 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 027 | Batch: 000 | Loss: 0.02276 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 027 | Batch: 100 | Loss: 0.00451 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 027 | Batch: 200 | Loss: 0.01753 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 027 | Batch: 300 | Loss: 0.01016 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 027 | Batch: 400 | Loss: 0.01871 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 027 | Batch: 000 | Loss: 0.00487 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 027 | Batch: 100 | Loss: 0.00544 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 027 | Batch: 200 | Loss: 0.03473 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 027 | Batch: 300 | Loss: 0.05636 | Correct: 124/128\n",
      "Estimator: 007 | Epoch: 027 | Batch: 400 | Loss: 0.07629 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 027 | Batch: 000 | Loss: 0.05618 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 027 | Batch: 100 | Loss: 0.01284 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 027 | Batch: 200 | Loss: 0.00670 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 027 | Batch: 300 | Loss: 0.02858 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 027 | Batch: 400 | Loss: 0.00934 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 027 | Batch: 000 | Loss: 0.01754 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 027 | Batch: 100 | Loss: 0.01685 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 027 | Batch: 200 | Loss: 0.01525 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 027 | Batch: 300 | Loss: 0.01932 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 027 | Batch: 400 | Loss: 0.01725 | Correct: 127/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:56:12,149 - INFO: Epoch: 027 | Validation Acc: 98.550 % | Historical Best: 98.650 %\n",
      "2022-09-25 01:56:12,149 - INFO: Epoch: 027 | Validation Acc: 98.550 % | Historical Best: 98.650 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 028 | Batch: 000 | Loss: 0.05195 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 028 | Batch: 100 | Loss: 0.01433 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 028 | Batch: 200 | Loss: 0.01557 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 028 | Batch: 300 | Loss: 0.01143 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 028 | Batch: 400 | Loss: 0.00834 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 028 | Batch: 000 | Loss: 0.00605 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 028 | Batch: 100 | Loss: 0.05165 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 028 | Batch: 200 | Loss: 0.03256 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 028 | Batch: 300 | Loss: 0.01840 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 028 | Batch: 400 | Loss: 0.05377 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 028 | Batch: 000 | Loss: 0.02869 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 028 | Batch: 100 | Loss: 0.00947 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 028 | Batch: 200 | Loss: 0.01007 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 028 | Batch: 300 | Loss: 0.00561 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 028 | Batch: 400 | Loss: 0.06359 | Correct: 124/128\n",
      "Estimator: 003 | Epoch: 028 | Batch: 000 | Loss: 0.02116 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 028 | Batch: 100 | Loss: 0.01694 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 028 | Batch: 200 | Loss: 0.00691 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 028 | Batch: 300 | Loss: 0.02942 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 028 | Batch: 400 | Loss: 0.05092 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 028 | Batch: 000 | Loss: 0.02552 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 028 | Batch: 100 | Loss: 0.01500 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 028 | Batch: 200 | Loss: 0.06679 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 028 | Batch: 300 | Loss: 0.00297 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 028 | Batch: 400 | Loss: 0.02406 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 028 | Batch: 000 | Loss: 0.01294 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 028 | Batch: 100 | Loss: 0.04489 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 028 | Batch: 200 | Loss: 0.02074 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 028 | Batch: 300 | Loss: 0.02232 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 028 | Batch: 400 | Loss: 0.01543 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 028 | Batch: 000 | Loss: 0.03399 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 028 | Batch: 100 | Loss: 0.00642 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 028 | Batch: 200 | Loss: 0.04437 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 028 | Batch: 300 | Loss: 0.01448 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 028 | Batch: 400 | Loss: 0.02246 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 028 | Batch: 000 | Loss: 0.00624 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 028 | Batch: 100 | Loss: 0.02615 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 028 | Batch: 200 | Loss: 0.01183 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 028 | Batch: 300 | Loss: 0.00734 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 028 | Batch: 400 | Loss: 0.01047 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 028 | Batch: 000 | Loss: 0.00617 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 028 | Batch: 100 | Loss: 0.03094 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 028 | Batch: 200 | Loss: 0.00679 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 028 | Batch: 300 | Loss: 0.02190 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 028 | Batch: 400 | Loss: 0.01740 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 028 | Batch: 000 | Loss: 0.02507 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 028 | Batch: 100 | Loss: 0.04631 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 028 | Batch: 200 | Loss: 0.03935 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 028 | Batch: 300 | Loss: 0.02876 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 028 | Batch: 400 | Loss: 0.02430 | Correct: 126/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:57:51,209 - INFO: Epoch: 028 | Validation Acc: 98.640 % | Historical Best: 98.650 %\n",
      "2022-09-25 01:57:51,209 - INFO: Epoch: 028 | Validation Acc: 98.640 % | Historical Best: 98.650 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 029 | Batch: 000 | Loss: 0.00961 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 029 | Batch: 100 | Loss: 0.02617 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 029 | Batch: 200 | Loss: 0.00897 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 029 | Batch: 300 | Loss: 0.03533 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 029 | Batch: 400 | Loss: 0.02560 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 029 | Batch: 000 | Loss: 0.00919 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 029 | Batch: 100 | Loss: 0.01685 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 029 | Batch: 200 | Loss: 0.03421 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 029 | Batch: 300 | Loss: 0.01594 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 029 | Batch: 400 | Loss: 0.00431 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 029 | Batch: 000 | Loss: 0.10051 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 029 | Batch: 100 | Loss: 0.04556 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 029 | Batch: 200 | Loss: 0.01681 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 029 | Batch: 300 | Loss: 0.01691 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 029 | Batch: 400 | Loss: 0.01751 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 029 | Batch: 000 | Loss: 0.01229 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 029 | Batch: 100 | Loss: 0.02437 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 029 | Batch: 200 | Loss: 0.02015 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 029 | Batch: 300 | Loss: 0.01816 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 029 | Batch: 400 | Loss: 0.03067 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 029 | Batch: 000 | Loss: 0.03297 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 029 | Batch: 100 | Loss: 0.05812 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 029 | Batch: 200 | Loss: 0.03641 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 029 | Batch: 300 | Loss: 0.01522 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 029 | Batch: 400 | Loss: 0.00938 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 029 | Batch: 000 | Loss: 0.02521 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 029 | Batch: 100 | Loss: 0.00534 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 029 | Batch: 200 | Loss: 0.02304 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 029 | Batch: 300 | Loss: 0.02513 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 029 | Batch: 400 | Loss: 0.00917 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 029 | Batch: 000 | Loss: 0.01081 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 029 | Batch: 100 | Loss: 0.01230 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 029 | Batch: 200 | Loss: 0.02424 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 029 | Batch: 300 | Loss: 0.02438 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 029 | Batch: 400 | Loss: 0.02368 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 029 | Batch: 000 | Loss: 0.01956 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 029 | Batch: 100 | Loss: 0.00474 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 029 | Batch: 200 | Loss: 0.02056 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 029 | Batch: 300 | Loss: 0.00223 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 029 | Batch: 400 | Loss: 0.00741 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 029 | Batch: 000 | Loss: 0.01922 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 029 | Batch: 100 | Loss: 0.01061 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 029 | Batch: 200 | Loss: 0.04555 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 029 | Batch: 300 | Loss: 0.06051 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 029 | Batch: 400 | Loss: 0.03834 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 029 | Batch: 000 | Loss: 0.01240 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 029 | Batch: 100 | Loss: 0.02614 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 029 | Batch: 200 | Loss: 0.02936 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 029 | Batch: 300 | Loss: 0.02653 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 029 | Batch: 400 | Loss: 0.02111 | Correct: 127/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 01:59:29,997 - INFO: Epoch: 029 | Validation Acc: 98.580 % | Historical Best: 98.650 %\n",
      "2022-09-25 01:59:29,997 - INFO: Epoch: 029 | Validation Acc: 98.580 % | Historical Best: 98.650 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 030 | Batch: 000 | Loss: 0.00565 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 030 | Batch: 100 | Loss: 0.03646 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 030 | Batch: 200 | Loss: 0.01152 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 030 | Batch: 300 | Loss: 0.05145 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 030 | Batch: 400 | Loss: 0.00753 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 030 | Batch: 000 | Loss: 0.02937 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 030 | Batch: 100 | Loss: 0.02009 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 030 | Batch: 200 | Loss: 0.01548 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 030 | Batch: 300 | Loss: 0.02037 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 030 | Batch: 400 | Loss: 0.01696 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 030 | Batch: 000 | Loss: 0.01896 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 030 | Batch: 100 | Loss: 0.02357 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 030 | Batch: 200 | Loss: 0.00963 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 030 | Batch: 300 | Loss: 0.06465 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 030 | Batch: 400 | Loss: 0.03465 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 030 | Batch: 000 | Loss: 0.02320 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 030 | Batch: 100 | Loss: 0.01699 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 030 | Batch: 200 | Loss: 0.00646 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 030 | Batch: 300 | Loss: 0.00283 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 030 | Batch: 400 | Loss: 0.04023 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 030 | Batch: 000 | Loss: 0.02088 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 030 | Batch: 100 | Loss: 0.00641 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 030 | Batch: 200 | Loss: 0.01623 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 030 | Batch: 300 | Loss: 0.02312 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 030 | Batch: 400 | Loss: 0.03202 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 030 | Batch: 000 | Loss: 0.03933 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 030 | Batch: 100 | Loss: 0.05717 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 030 | Batch: 200 | Loss: 0.05191 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 030 | Batch: 300 | Loss: 0.02811 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 030 | Batch: 400 | Loss: 0.02867 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 030 | Batch: 000 | Loss: 0.01570 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 030 | Batch: 100 | Loss: 0.00503 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 030 | Batch: 200 | Loss: 0.00758 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 030 | Batch: 300 | Loss: 0.00796 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 030 | Batch: 400 | Loss: 0.04060 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 030 | Batch: 000 | Loss: 0.03948 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 030 | Batch: 100 | Loss: 0.00229 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 030 | Batch: 200 | Loss: 0.02782 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 030 | Batch: 300 | Loss: 0.01427 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 030 | Batch: 400 | Loss: 0.02355 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 030 | Batch: 000 | Loss: 0.03608 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 030 | Batch: 100 | Loss: 0.02919 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 030 | Batch: 200 | Loss: 0.00739 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 030 | Batch: 300 | Loss: 0.03960 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 030 | Batch: 400 | Loss: 0.02012 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 030 | Batch: 000 | Loss: 0.00679 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 030 | Batch: 100 | Loss: 0.00603 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 030 | Batch: 200 | Loss: 0.01359 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 030 | Batch: 300 | Loss: 0.01405 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 030 | Batch: 400 | Loss: 0.00822 | Correct: 128/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 02:01:08,959 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 02:01:08,959 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 02:01:08,973 - INFO: Epoch: 030 | Validation Acc: 98.660 % | Historical Best: 98.660 %\n",
      "2022-09-25 02:01:08,973 - INFO: Epoch: 030 | Validation Acc: 98.660 % | Historical Best: 98.660 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 031 | Batch: 000 | Loss: 0.00586 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 031 | Batch: 100 | Loss: 0.03150 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 031 | Batch: 200 | Loss: 0.02088 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 031 | Batch: 300 | Loss: 0.02272 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 031 | Batch: 400 | Loss: 0.04404 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 031 | Batch: 000 | Loss: 0.01452 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 031 | Batch: 100 | Loss: 0.01466 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 031 | Batch: 200 | Loss: 0.02715 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 031 | Batch: 300 | Loss: 0.00783 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 031 | Batch: 400 | Loss: 0.06025 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 031 | Batch: 000 | Loss: 0.02089 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 031 | Batch: 100 | Loss: 0.00764 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 031 | Batch: 200 | Loss: 0.01425 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 031 | Batch: 300 | Loss: 0.01966 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 031 | Batch: 400 | Loss: 0.02120 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 031 | Batch: 000 | Loss: 0.02462 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 031 | Batch: 100 | Loss: 0.02612 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 031 | Batch: 200 | Loss: 0.02904 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 031 | Batch: 300 | Loss: 0.02624 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 031 | Batch: 400 | Loss: 0.00344 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 031 | Batch: 000 | Loss: 0.03430 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 031 | Batch: 100 | Loss: 0.00441 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 031 | Batch: 200 | Loss: 0.02641 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 031 | Batch: 300 | Loss: 0.00538 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 031 | Batch: 400 | Loss: 0.11699 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 031 | Batch: 000 | Loss: 0.02041 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 031 | Batch: 100 | Loss: 0.08933 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 031 | Batch: 200 | Loss: 0.04246 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 031 | Batch: 300 | Loss: 0.02728 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 031 | Batch: 400 | Loss: 0.07980 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 031 | Batch: 000 | Loss: 0.02800 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 031 | Batch: 100 | Loss: 0.03198 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 031 | Batch: 200 | Loss: 0.00519 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 031 | Batch: 300 | Loss: 0.01144 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 031 | Batch: 400 | Loss: 0.05630 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 031 | Batch: 000 | Loss: 0.00952 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 031 | Batch: 100 | Loss: 0.03670 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 031 | Batch: 200 | Loss: 0.04179 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 031 | Batch: 300 | Loss: 0.03080 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 031 | Batch: 400 | Loss: 0.05859 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 031 | Batch: 000 | Loss: 0.01972 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 031 | Batch: 100 | Loss: 0.02024 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 031 | Batch: 200 | Loss: 0.00911 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 031 | Batch: 300 | Loss: 0.01394 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 031 | Batch: 400 | Loss: 0.00871 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 031 | Batch: 000 | Loss: 0.07049 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 031 | Batch: 100 | Loss: 0.00311 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 031 | Batch: 200 | Loss: 0.00547 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 031 | Batch: 300 | Loss: 0.00776 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 031 | Batch: 400 | Loss: 0.04305 | Correct: 126/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 02:02:47,599 - INFO: Epoch: 031 | Validation Acc: 98.610 % | Historical Best: 98.660 %\n",
      "2022-09-25 02:02:47,599 - INFO: Epoch: 031 | Validation Acc: 98.610 % | Historical Best: 98.660 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 032 | Batch: 000 | Loss: 0.01300 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 032 | Batch: 100 | Loss: 0.02485 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 032 | Batch: 200 | Loss: 0.02707 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 032 | Batch: 300 | Loss: 0.01436 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 032 | Batch: 400 | Loss: 0.01621 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 032 | Batch: 000 | Loss: 0.01388 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 032 | Batch: 100 | Loss: 0.01771 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 032 | Batch: 200 | Loss: 0.04555 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 032 | Batch: 300 | Loss: 0.00591 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 032 | Batch: 400 | Loss: 0.00765 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 032 | Batch: 000 | Loss: 0.02598 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 032 | Batch: 100 | Loss: 0.01188 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 032 | Batch: 200 | Loss: 0.01105 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 032 | Batch: 300 | Loss: 0.00729 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 032 | Batch: 400 | Loss: 0.02808 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 032 | Batch: 000 | Loss: 0.01055 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 032 | Batch: 100 | Loss: 0.00448 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 032 | Batch: 200 | Loss: 0.00310 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 032 | Batch: 300 | Loss: 0.01080 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 032 | Batch: 400 | Loss: 0.02906 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 032 | Batch: 000 | Loss: 0.01458 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 032 | Batch: 100 | Loss: 0.01378 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 032 | Batch: 200 | Loss: 0.00657 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 032 | Batch: 300 | Loss: 0.00341 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 032 | Batch: 400 | Loss: 0.02676 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 032 | Batch: 000 | Loss: 0.01413 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 032 | Batch: 100 | Loss: 0.01844 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 032 | Batch: 200 | Loss: 0.02462 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 032 | Batch: 300 | Loss: 0.02049 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 032 | Batch: 400 | Loss: 0.02254 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 032 | Batch: 000 | Loss: 0.01992 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 032 | Batch: 100 | Loss: 0.00272 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 032 | Batch: 200 | Loss: 0.01728 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 032 | Batch: 300 | Loss: 0.01652 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 032 | Batch: 400 | Loss: 0.00622 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 032 | Batch: 000 | Loss: 0.03689 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 032 | Batch: 100 | Loss: 0.01403 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 032 | Batch: 200 | Loss: 0.02854 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 032 | Batch: 300 | Loss: 0.02672 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 032 | Batch: 400 | Loss: 0.03259 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 032 | Batch: 000 | Loss: 0.01974 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 032 | Batch: 100 | Loss: 0.00783 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 032 | Batch: 200 | Loss: 0.00768 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 032 | Batch: 300 | Loss: 0.01035 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 032 | Batch: 400 | Loss: 0.02527 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 032 | Batch: 000 | Loss: 0.02953 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 032 | Batch: 100 | Loss: 0.00680 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 032 | Batch: 200 | Loss: 0.02144 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 032 | Batch: 300 | Loss: 0.01638 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 032 | Batch: 400 | Loss: 0.01344 | Correct: 127/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 02:04:26,390 - INFO: Epoch: 032 | Validation Acc: 98.630 % | Historical Best: 98.660 %\n",
      "2022-09-25 02:04:26,390 - INFO: Epoch: 032 | Validation Acc: 98.630 % | Historical Best: 98.660 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 033 | Batch: 000 | Loss: 0.01613 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 033 | Batch: 100 | Loss: 0.02886 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 033 | Batch: 200 | Loss: 0.04734 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 033 | Batch: 300 | Loss: 0.03387 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 033 | Batch: 400 | Loss: 0.04404 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 033 | Batch: 000 | Loss: 0.01852 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 033 | Batch: 100 | Loss: 0.00814 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 033 | Batch: 200 | Loss: 0.00433 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 033 | Batch: 300 | Loss: 0.02455 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 033 | Batch: 400 | Loss: 0.04035 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 033 | Batch: 000 | Loss: 0.03594 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 033 | Batch: 100 | Loss: 0.00504 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 033 | Batch: 200 | Loss: 0.01593 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 033 | Batch: 300 | Loss: 0.01129 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 033 | Batch: 400 | Loss: 0.00880 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 033 | Batch: 000 | Loss: 0.01435 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 033 | Batch: 100 | Loss: 0.01476 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 033 | Batch: 200 | Loss: 0.02230 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 033 | Batch: 300 | Loss: 0.02529 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 033 | Batch: 400 | Loss: 0.02938 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 033 | Batch: 000 | Loss: 0.01886 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 033 | Batch: 100 | Loss: 0.00714 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 033 | Batch: 200 | Loss: 0.01514 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 033 | Batch: 300 | Loss: 0.03284 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 033 | Batch: 400 | Loss: 0.01727 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 033 | Batch: 000 | Loss: 0.00982 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 033 | Batch: 100 | Loss: 0.01429 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 033 | Batch: 200 | Loss: 0.01119 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 033 | Batch: 300 | Loss: 0.03643 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 033 | Batch: 400 | Loss: 0.02634 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 033 | Batch: 000 | Loss: 0.01361 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 033 | Batch: 100 | Loss: 0.05152 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 033 | Batch: 200 | Loss: 0.01260 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 033 | Batch: 300 | Loss: 0.03706 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 033 | Batch: 400 | Loss: 0.04906 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 033 | Batch: 000 | Loss: 0.01011 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 033 | Batch: 100 | Loss: 0.01374 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 033 | Batch: 200 | Loss: 0.02500 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 033 | Batch: 300 | Loss: 0.01483 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 033 | Batch: 400 | Loss: 0.00332 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 033 | Batch: 000 | Loss: 0.01526 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 033 | Batch: 100 | Loss: 0.00802 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 033 | Batch: 200 | Loss: 0.03699 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 033 | Batch: 300 | Loss: 0.00870 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 033 | Batch: 400 | Loss: 0.04110 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 033 | Batch: 000 | Loss: 0.01677 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 033 | Batch: 100 | Loss: 0.02590 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 033 | Batch: 200 | Loss: 0.04178 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 033 | Batch: 300 | Loss: 0.04835 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 033 | Batch: 400 | Loss: 0.01549 | Correct: 128/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 02:06:05,296 - INFO: Epoch: 033 | Validation Acc: 98.620 % | Historical Best: 98.660 %\n",
      "2022-09-25 02:06:05,296 - INFO: Epoch: 033 | Validation Acc: 98.620 % | Historical Best: 98.660 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 034 | Batch: 000 | Loss: 0.03570 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 034 | Batch: 100 | Loss: 0.02304 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 034 | Batch: 200 | Loss: 0.01750 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 034 | Batch: 300 | Loss: 0.03860 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 034 | Batch: 400 | Loss: 0.02674 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 034 | Batch: 000 | Loss: 0.05056 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 034 | Batch: 100 | Loss: 0.00244 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 034 | Batch: 200 | Loss: 0.03093 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 034 | Batch: 300 | Loss: 0.00637 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 034 | Batch: 400 | Loss: 0.01500 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 034 | Batch: 000 | Loss: 0.00566 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 034 | Batch: 100 | Loss: 0.00341 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 034 | Batch: 200 | Loss: 0.00415 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 034 | Batch: 300 | Loss: 0.02645 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 034 | Batch: 400 | Loss: 0.00853 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 034 | Batch: 000 | Loss: 0.00752 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 034 | Batch: 100 | Loss: 0.01816 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 034 | Batch: 200 | Loss: 0.01404 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 034 | Batch: 300 | Loss: 0.02376 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 034 | Batch: 400 | Loss: 0.03574 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 034 | Batch: 000 | Loss: 0.01517 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 034 | Batch: 100 | Loss: 0.00648 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 034 | Batch: 200 | Loss: 0.00842 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 034 | Batch: 300 | Loss: 0.02550 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 034 | Batch: 400 | Loss: 0.00934 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 034 | Batch: 000 | Loss: 0.00615 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 034 | Batch: 100 | Loss: 0.02015 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 034 | Batch: 200 | Loss: 0.01652 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 034 | Batch: 300 | Loss: 0.01546 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 034 | Batch: 400 | Loss: 0.01229 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 034 | Batch: 000 | Loss: 0.00486 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 034 | Batch: 100 | Loss: 0.04403 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 034 | Batch: 200 | Loss: 0.00447 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 034 | Batch: 300 | Loss: 0.04122 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 034 | Batch: 400 | Loss: 0.02328 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 034 | Batch: 000 | Loss: 0.02439 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 034 | Batch: 100 | Loss: 0.06396 | Correct: 123/128\n",
      "Estimator: 007 | Epoch: 034 | Batch: 200 | Loss: 0.00352 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 034 | Batch: 300 | Loss: 0.03804 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 034 | Batch: 400 | Loss: 0.01275 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 034 | Batch: 000 | Loss: 0.01649 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 034 | Batch: 100 | Loss: 0.01034 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 034 | Batch: 200 | Loss: 0.01865 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 034 | Batch: 300 | Loss: 0.02980 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 034 | Batch: 400 | Loss: 0.00473 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 034 | Batch: 000 | Loss: 0.01359 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 034 | Batch: 100 | Loss: 0.01022 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 034 | Batch: 200 | Loss: 0.02109 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 034 | Batch: 300 | Loss: 0.03677 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 034 | Batch: 400 | Loss: 0.03283 | Correct: 126/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 02:07:43,684 - INFO: Epoch: 034 | Validation Acc: 98.530 % | Historical Best: 98.660 %\n",
      "2022-09-25 02:07:43,684 - INFO: Epoch: 034 | Validation Acc: 98.530 % | Historical Best: 98.660 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 035 | Batch: 000 | Loss: 0.02541 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 035 | Batch: 100 | Loss: 0.04620 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 035 | Batch: 200 | Loss: 0.01099 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 035 | Batch: 300 | Loss: 0.00594 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 035 | Batch: 400 | Loss: 0.00598 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 035 | Batch: 000 | Loss: 0.00958 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 035 | Batch: 100 | Loss: 0.01457 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 035 | Batch: 200 | Loss: 0.00625 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 035 | Batch: 300 | Loss: 0.00475 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 035 | Batch: 400 | Loss: 0.02389 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 035 | Batch: 000 | Loss: 0.01080 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 035 | Batch: 100 | Loss: 0.00930 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 035 | Batch: 200 | Loss: 0.01595 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 035 | Batch: 300 | Loss: 0.02955 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 035 | Batch: 400 | Loss: 0.01136 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 035 | Batch: 000 | Loss: 0.02557 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 035 | Batch: 100 | Loss: 0.01260 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 035 | Batch: 200 | Loss: 0.00761 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 035 | Batch: 300 | Loss: 0.01650 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 035 | Batch: 400 | Loss: 0.02867 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 035 | Batch: 000 | Loss: 0.00426 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 035 | Batch: 100 | Loss: 0.01335 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 035 | Batch: 200 | Loss: 0.02866 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 035 | Batch: 300 | Loss: 0.06217 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 035 | Batch: 400 | Loss: 0.02087 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 035 | Batch: 000 | Loss: 0.00846 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 035 | Batch: 100 | Loss: 0.04748 | Correct: 124/128\n",
      "Estimator: 005 | Epoch: 035 | Batch: 200 | Loss: 0.01495 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 035 | Batch: 300 | Loss: 0.05150 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 035 | Batch: 400 | Loss: 0.02991 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 035 | Batch: 000 | Loss: 0.00681 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 035 | Batch: 100 | Loss: 0.01099 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 035 | Batch: 200 | Loss: 0.02548 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 035 | Batch: 300 | Loss: 0.04565 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 035 | Batch: 400 | Loss: 0.01682 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 035 | Batch: 000 | Loss: 0.01128 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 035 | Batch: 100 | Loss: 0.00691 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 035 | Batch: 200 | Loss: 0.03782 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 035 | Batch: 300 | Loss: 0.01829 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 035 | Batch: 400 | Loss: 0.03437 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 035 | Batch: 000 | Loss: 0.01674 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 035 | Batch: 100 | Loss: 0.03534 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 035 | Batch: 200 | Loss: 0.03559 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 035 | Batch: 300 | Loss: 0.04518 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 035 | Batch: 400 | Loss: 0.02258 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 035 | Batch: 000 | Loss: 0.02814 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 035 | Batch: 100 | Loss: 0.01023 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 035 | Batch: 200 | Loss: 0.00732 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 035 | Batch: 300 | Loss: 0.02002 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 035 | Batch: 400 | Loss: 0.03206 | Correct: 126/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 02:09:22,248 - INFO: Epoch: 035 | Validation Acc: 98.640 % | Historical Best: 98.660 %\n",
      "2022-09-25 02:09:22,248 - INFO: Epoch: 035 | Validation Acc: 98.640 % | Historical Best: 98.660 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 036 | Batch: 000 | Loss: 0.01275 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 036 | Batch: 100 | Loss: 0.02009 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 036 | Batch: 200 | Loss: 0.03584 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 036 | Batch: 300 | Loss: 0.00789 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 036 | Batch: 400 | Loss: 0.00454 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 036 | Batch: 000 | Loss: 0.04204 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 036 | Batch: 100 | Loss: 0.00806 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 036 | Batch: 200 | Loss: 0.01396 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 036 | Batch: 300 | Loss: 0.04766 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 036 | Batch: 400 | Loss: 0.04141 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 036 | Batch: 000 | Loss: 0.03824 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 036 | Batch: 100 | Loss: 0.02379 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 036 | Batch: 200 | Loss: 0.01341 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 036 | Batch: 300 | Loss: 0.02861 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 036 | Batch: 400 | Loss: 0.01395 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 036 | Batch: 000 | Loss: 0.00718 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 036 | Batch: 100 | Loss: 0.00486 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 036 | Batch: 200 | Loss: 0.03677 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 036 | Batch: 300 | Loss: 0.05505 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 036 | Batch: 400 | Loss: 0.01009 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 036 | Batch: 000 | Loss: 0.07789 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 036 | Batch: 100 | Loss: 0.02476 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 036 | Batch: 200 | Loss: 0.01617 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 036 | Batch: 300 | Loss: 0.03776 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 036 | Batch: 400 | Loss: 0.03291 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 036 | Batch: 000 | Loss: 0.01390 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 036 | Batch: 100 | Loss: 0.01313 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 036 | Batch: 200 | Loss: 0.00429 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 036 | Batch: 300 | Loss: 0.01843 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 036 | Batch: 400 | Loss: 0.02203 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 036 | Batch: 000 | Loss: 0.02541 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 036 | Batch: 100 | Loss: 0.03887 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 036 | Batch: 200 | Loss: 0.04027 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 036 | Batch: 300 | Loss: 0.03035 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 036 | Batch: 400 | Loss: 0.02479 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 036 | Batch: 000 | Loss: 0.02887 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 036 | Batch: 100 | Loss: 0.00808 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 036 | Batch: 200 | Loss: 0.01882 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 036 | Batch: 300 | Loss: 0.01353 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 036 | Batch: 400 | Loss: 0.03255 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 036 | Batch: 000 | Loss: 0.01202 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 036 | Batch: 100 | Loss: 0.04573 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 036 | Batch: 200 | Loss: 0.05298 | Correct: 124/128\n",
      "Estimator: 008 | Epoch: 036 | Batch: 300 | Loss: 0.01803 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 036 | Batch: 400 | Loss: 0.04118 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 036 | Batch: 000 | Loss: 0.01359 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 036 | Batch: 100 | Loss: 0.01176 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 036 | Batch: 200 | Loss: 0.04291 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 036 | Batch: 300 | Loss: 0.03789 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 036 | Batch: 400 | Loss: 0.05622 | Correct: 126/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 02:11:01,195 - INFO: Epoch: 036 | Validation Acc: 98.620 % | Historical Best: 98.660 %\n",
      "2022-09-25 02:11:01,195 - INFO: Epoch: 036 | Validation Acc: 98.620 % | Historical Best: 98.660 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 037 | Batch: 000 | Loss: 0.03010 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 037 | Batch: 100 | Loss: 0.00765 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 037 | Batch: 200 | Loss: 0.03482 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 037 | Batch: 300 | Loss: 0.02760 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 037 | Batch: 400 | Loss: 0.00818 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 037 | Batch: 000 | Loss: 0.00826 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 037 | Batch: 100 | Loss: 0.02522 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 037 | Batch: 200 | Loss: 0.00359 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 037 | Batch: 300 | Loss: 0.01070 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 037 | Batch: 400 | Loss: 0.02358 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 037 | Batch: 000 | Loss: 0.00261 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 037 | Batch: 100 | Loss: 0.04310 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 037 | Batch: 200 | Loss: 0.01617 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 037 | Batch: 300 | Loss: 0.02280 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 037 | Batch: 400 | Loss: 0.06539 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 037 | Batch: 000 | Loss: 0.00495 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 037 | Batch: 100 | Loss: 0.02932 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 037 | Batch: 200 | Loss: 0.01063 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 037 | Batch: 300 | Loss: 0.02410 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 037 | Batch: 400 | Loss: 0.05552 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 037 | Batch: 000 | Loss: 0.01998 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 037 | Batch: 100 | Loss: 0.01157 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 037 | Batch: 200 | Loss: 0.02390 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 037 | Batch: 300 | Loss: 0.03710 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 037 | Batch: 400 | Loss: 0.01311 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 037 | Batch: 000 | Loss: 0.03615 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 037 | Batch: 100 | Loss: 0.00667 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 037 | Batch: 200 | Loss: 0.01957 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 037 | Batch: 300 | Loss: 0.01499 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 037 | Batch: 400 | Loss: 0.00572 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 037 | Batch: 000 | Loss: 0.02884 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 037 | Batch: 100 | Loss: 0.01573 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 037 | Batch: 200 | Loss: 0.00249 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 037 | Batch: 300 | Loss: 0.00600 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 037 | Batch: 400 | Loss: 0.04310 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 037 | Batch: 000 | Loss: 0.03913 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 037 | Batch: 100 | Loss: 0.01817 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 037 | Batch: 200 | Loss: 0.00827 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 037 | Batch: 300 | Loss: 0.01383 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 037 | Batch: 400 | Loss: 0.04253 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 037 | Batch: 000 | Loss: 0.02209 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 037 | Batch: 100 | Loss: 0.01869 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 037 | Batch: 200 | Loss: 0.01254 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 037 | Batch: 300 | Loss: 0.01510 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 037 | Batch: 400 | Loss: 0.01396 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 037 | Batch: 000 | Loss: 0.00969 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 037 | Batch: 100 | Loss: 0.02321 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 037 | Batch: 200 | Loss: 0.02328 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 037 | Batch: 300 | Loss: 0.02462 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 037 | Batch: 400 | Loss: 0.01197 | Correct: 128/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 02:12:39,274 - INFO: Epoch: 037 | Validation Acc: 98.560 % | Historical Best: 98.660 %\n",
      "2022-09-25 02:12:39,274 - INFO: Epoch: 037 | Validation Acc: 98.560 % | Historical Best: 98.660 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 038 | Batch: 000 | Loss: 0.00932 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 038 | Batch: 100 | Loss: 0.01225 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 038 | Batch: 200 | Loss: 0.02648 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 038 | Batch: 300 | Loss: 0.02804 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 038 | Batch: 400 | Loss: 0.05822 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 038 | Batch: 000 | Loss: 0.00619 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 038 | Batch: 100 | Loss: 0.06170 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 038 | Batch: 200 | Loss: 0.01702 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 038 | Batch: 300 | Loss: 0.04628 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 038 | Batch: 400 | Loss: 0.10063 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 038 | Batch: 000 | Loss: 0.02227 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 038 | Batch: 100 | Loss: 0.02509 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 038 | Batch: 200 | Loss: 0.02581 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 038 | Batch: 300 | Loss: 0.01380 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 038 | Batch: 400 | Loss: 0.03119 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 038 | Batch: 000 | Loss: 0.01374 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 038 | Batch: 100 | Loss: 0.02449 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 038 | Batch: 200 | Loss: 0.02689 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 038 | Batch: 300 | Loss: 0.02195 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 038 | Batch: 400 | Loss: 0.01794 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 038 | Batch: 000 | Loss: 0.02240 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 038 | Batch: 100 | Loss: 0.02749 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 038 | Batch: 200 | Loss: 0.00690 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 038 | Batch: 300 | Loss: 0.01107 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 038 | Batch: 400 | Loss: 0.01536 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 038 | Batch: 000 | Loss: 0.02068 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 038 | Batch: 100 | Loss: 0.03708 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 038 | Batch: 200 | Loss: 0.02113 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 038 | Batch: 300 | Loss: 0.02566 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 038 | Batch: 400 | Loss: 0.02500 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 038 | Batch: 000 | Loss: 0.01449 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 038 | Batch: 100 | Loss: 0.02295 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 038 | Batch: 200 | Loss: 0.10452 | Correct: 124/128\n",
      "Estimator: 006 | Epoch: 038 | Batch: 300 | Loss: 0.01252 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 038 | Batch: 400 | Loss: 0.03621 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 038 | Batch: 000 | Loss: 0.04292 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 038 | Batch: 100 | Loss: 0.00829 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 038 | Batch: 200 | Loss: 0.02622 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 038 | Batch: 300 | Loss: 0.01231 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 038 | Batch: 400 | Loss: 0.02036 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 038 | Batch: 000 | Loss: 0.02284 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 038 | Batch: 100 | Loss: 0.00835 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 038 | Batch: 200 | Loss: 0.01390 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 038 | Batch: 300 | Loss: 0.04312 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 038 | Batch: 400 | Loss: 0.00767 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 038 | Batch: 000 | Loss: 0.04769 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 038 | Batch: 100 | Loss: 0.00831 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 038 | Batch: 200 | Loss: 0.03350 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 038 | Batch: 300 | Loss: 0.00869 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 038 | Batch: 400 | Loss: 0.01297 | Correct: 127/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 02:14:17,268 - INFO: Epoch: 038 | Validation Acc: 98.630 % | Historical Best: 98.660 %\n",
      "2022-09-25 02:14:17,268 - INFO: Epoch: 038 | Validation Acc: 98.630 % | Historical Best: 98.660 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 039 | Batch: 000 | Loss: 0.00600 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 039 | Batch: 100 | Loss: 0.02432 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 039 | Batch: 200 | Loss: 0.00903 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 039 | Batch: 300 | Loss: 0.00537 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 039 | Batch: 400 | Loss: 0.03180 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 039 | Batch: 000 | Loss: 0.02250 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 039 | Batch: 100 | Loss: 0.03094 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 039 | Batch: 200 | Loss: 0.01034 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 039 | Batch: 300 | Loss: 0.04084 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 039 | Batch: 400 | Loss: 0.02887 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 039 | Batch: 000 | Loss: 0.02839 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 039 | Batch: 100 | Loss: 0.02925 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 039 | Batch: 200 | Loss: 0.02859 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 039 | Batch: 300 | Loss: 0.00999 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 039 | Batch: 400 | Loss: 0.04396 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 039 | Batch: 000 | Loss: 0.00722 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 039 | Batch: 100 | Loss: 0.00422 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 039 | Batch: 200 | Loss: 0.01539 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 039 | Batch: 300 | Loss: 0.02051 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 039 | Batch: 400 | Loss: 0.01779 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 039 | Batch: 000 | Loss: 0.05599 | Correct: 124/128\n",
      "Estimator: 004 | Epoch: 039 | Batch: 100 | Loss: 0.01360 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 039 | Batch: 200 | Loss: 0.01165 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 039 | Batch: 300 | Loss: 0.04732 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 039 | Batch: 400 | Loss: 0.03376 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 039 | Batch: 000 | Loss: 0.01118 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 039 | Batch: 100 | Loss: 0.00906 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 039 | Batch: 200 | Loss: 0.00505 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 039 | Batch: 300 | Loss: 0.02053 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 039 | Batch: 400 | Loss: 0.00305 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 039 | Batch: 000 | Loss: 0.02285 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 039 | Batch: 100 | Loss: 0.02479 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 039 | Batch: 200 | Loss: 0.03423 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 039 | Batch: 300 | Loss: 0.02446 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 039 | Batch: 400 | Loss: 0.04993 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 039 | Batch: 000 | Loss: 0.00609 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 039 | Batch: 100 | Loss: 0.02232 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 039 | Batch: 200 | Loss: 0.03029 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 039 | Batch: 300 | Loss: 0.03885 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 039 | Batch: 400 | Loss: 0.01178 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 039 | Batch: 000 | Loss: 0.03146 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 039 | Batch: 100 | Loss: 0.01162 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 039 | Batch: 200 | Loss: 0.03213 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 039 | Batch: 300 | Loss: 0.05672 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 039 | Batch: 400 | Loss: 0.05191 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 039 | Batch: 000 | Loss: 0.01252 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 039 | Batch: 100 | Loss: 0.01062 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 039 | Batch: 200 | Loss: 0.00674 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 039 | Batch: 300 | Loss: 0.01036 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 039 | Batch: 400 | Loss: 0.01201 | Correct: 127/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 02:15:55,558 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 02:15:55,558 - INFO: Saving the model to `./VotingClassifier_MLP_10_ckpt.pth`\n",
      "2022-09-25 02:15:55,573 - INFO: Epoch: 039 | Validation Acc: 98.690 % | Historical Best: 98.690 %\n",
      "2022-09-25 02:15:55,573 - INFO: Epoch: 039 | Validation Acc: 98.690 % | Historical Best: 98.690 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 040 | Batch: 000 | Loss: 0.00474 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 040 | Batch: 100 | Loss: 0.02522 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 040 | Batch: 200 | Loss: 0.03100 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 040 | Batch: 300 | Loss: 0.01758 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 040 | Batch: 400 | Loss: 0.00411 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 040 | Batch: 000 | Loss: 0.01848 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 040 | Batch: 100 | Loss: 0.00642 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 040 | Batch: 200 | Loss: 0.01245 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 040 | Batch: 300 | Loss: 0.02009 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 040 | Batch: 400 | Loss: 0.03531 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 040 | Batch: 000 | Loss: 0.03718 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 040 | Batch: 100 | Loss: 0.01410 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 040 | Batch: 200 | Loss: 0.03374 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 040 | Batch: 300 | Loss: 0.01193 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 040 | Batch: 400 | Loss: 0.03236 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 040 | Batch: 000 | Loss: 0.02879 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 040 | Batch: 100 | Loss: 0.00858 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 040 | Batch: 200 | Loss: 0.00365 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 040 | Batch: 300 | Loss: 0.02345 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 040 | Batch: 400 | Loss: 0.01129 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 040 | Batch: 000 | Loss: 0.06821 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 040 | Batch: 100 | Loss: 0.01913 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 040 | Batch: 200 | Loss: 0.01923 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 040 | Batch: 300 | Loss: 0.01167 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 040 | Batch: 400 | Loss: 0.01651 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 040 | Batch: 000 | Loss: 0.06803 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 040 | Batch: 100 | Loss: 0.01935 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 040 | Batch: 200 | Loss: 0.00891 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 040 | Batch: 300 | Loss: 0.00859 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 040 | Batch: 400 | Loss: 0.07628 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 040 | Batch: 000 | Loss: 0.01315 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 040 | Batch: 100 | Loss: 0.01924 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 040 | Batch: 200 | Loss: 0.01057 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 040 | Batch: 300 | Loss: 0.00948 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 040 | Batch: 400 | Loss: 0.02275 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 040 | Batch: 000 | Loss: 0.02628 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 040 | Batch: 100 | Loss: 0.00328 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 040 | Batch: 200 | Loss: 0.00610 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 040 | Batch: 300 | Loss: 0.00417 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 040 | Batch: 400 | Loss: 0.01220 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 040 | Batch: 000 | Loss: 0.01033 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 040 | Batch: 100 | Loss: 0.00862 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 040 | Batch: 200 | Loss: 0.02365 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 040 | Batch: 300 | Loss: 0.00656 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 040 | Batch: 400 | Loss: 0.01615 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 040 | Batch: 000 | Loss: 0.01332 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 040 | Batch: 100 | Loss: 0.04153 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 040 | Batch: 200 | Loss: 0.01240 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 040 | Batch: 300 | Loss: 0.00382 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 040 | Batch: 400 | Loss: 0.01339 | Correct: 128/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 02:17:34,239 - INFO: Epoch: 040 | Validation Acc: 98.580 % | Historical Best: 98.690 %\n",
      "2022-09-25 02:17:34,239 - INFO: Epoch: 040 | Validation Acc: 98.580 % | Historical Best: 98.690 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 041 | Batch: 000 | Loss: 0.01334 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 041 | Batch: 100 | Loss: 0.03646 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 041 | Batch: 200 | Loss: 0.02005 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 041 | Batch: 300 | Loss: 0.01812 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 041 | Batch: 400 | Loss: 0.01086 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 041 | Batch: 000 | Loss: 0.02059 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 041 | Batch: 100 | Loss: 0.03147 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 041 | Batch: 200 | Loss: 0.02057 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 041 | Batch: 300 | Loss: 0.00986 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 041 | Batch: 400 | Loss: 0.01775 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 041 | Batch: 000 | Loss: 0.00641 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 041 | Batch: 100 | Loss: 0.00620 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 041 | Batch: 200 | Loss: 0.06562 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 041 | Batch: 300 | Loss: 0.04617 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 041 | Batch: 400 | Loss: 0.01104 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 041 | Batch: 000 | Loss: 0.00923 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 041 | Batch: 100 | Loss: 0.02012 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 041 | Batch: 200 | Loss: 0.00321 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 041 | Batch: 300 | Loss: 0.00751 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 041 | Batch: 400 | Loss: 0.03139 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 041 | Batch: 000 | Loss: 0.04851 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 041 | Batch: 100 | Loss: 0.01749 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 041 | Batch: 200 | Loss: 0.02160 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 041 | Batch: 300 | Loss: 0.03477 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 041 | Batch: 400 | Loss: 0.01425 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 041 | Batch: 000 | Loss: 0.01304 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 041 | Batch: 100 | Loss: 0.01875 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 041 | Batch: 200 | Loss: 0.00819 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 041 | Batch: 300 | Loss: 0.00372 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 041 | Batch: 400 | Loss: 0.02864 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 041 | Batch: 000 | Loss: 0.01045 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 041 | Batch: 100 | Loss: 0.01971 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 041 | Batch: 200 | Loss: 0.01218 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 041 | Batch: 300 | Loss: 0.02082 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 041 | Batch: 400 | Loss: 0.06911 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 041 | Batch: 000 | Loss: 0.02224 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 041 | Batch: 100 | Loss: 0.01997 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 041 | Batch: 200 | Loss: 0.01205 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 041 | Batch: 300 | Loss: 0.01331 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 041 | Batch: 400 | Loss: 0.02615 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 041 | Batch: 000 | Loss: 0.01237 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 041 | Batch: 100 | Loss: 0.01567 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 041 | Batch: 200 | Loss: 0.01378 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 041 | Batch: 300 | Loss: 0.03024 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 041 | Batch: 400 | Loss: 0.06115 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 041 | Batch: 000 | Loss: 0.02456 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 041 | Batch: 100 | Loss: 0.00948 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 041 | Batch: 200 | Loss: 0.05816 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 041 | Batch: 300 | Loss: 0.01658 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 041 | Batch: 400 | Loss: 0.01558 | Correct: 128/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 02:19:12,581 - INFO: Epoch: 041 | Validation Acc: 98.560 % | Historical Best: 98.690 %\n",
      "2022-09-25 02:19:12,581 - INFO: Epoch: 041 | Validation Acc: 98.560 % | Historical Best: 98.690 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 042 | Batch: 000 | Loss: 0.03762 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 042 | Batch: 100 | Loss: 0.00530 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 042 | Batch: 200 | Loss: 0.00216 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 042 | Batch: 300 | Loss: 0.00516 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 042 | Batch: 400 | Loss: 0.03517 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 042 | Batch: 000 | Loss: 0.00254 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 042 | Batch: 100 | Loss: 0.03270 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 042 | Batch: 200 | Loss: 0.02492 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 042 | Batch: 300 | Loss: 0.02800 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 042 | Batch: 400 | Loss: 0.03062 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 042 | Batch: 000 | Loss: 0.02003 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 042 | Batch: 100 | Loss: 0.02487 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 042 | Batch: 200 | Loss: 0.01194 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 042 | Batch: 300 | Loss: 0.00493 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 042 | Batch: 400 | Loss: 0.01034 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 042 | Batch: 000 | Loss: 0.03913 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 042 | Batch: 100 | Loss: 0.01035 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 042 | Batch: 200 | Loss: 0.02863 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 042 | Batch: 300 | Loss: 0.02072 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 042 | Batch: 400 | Loss: 0.01533 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 042 | Batch: 000 | Loss: 0.03736 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 042 | Batch: 100 | Loss: 0.01587 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 042 | Batch: 200 | Loss: 0.01311 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 042 | Batch: 300 | Loss: 0.01538 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 042 | Batch: 400 | Loss: 0.01897 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 042 | Batch: 000 | Loss: 0.02162 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 042 | Batch: 100 | Loss: 0.03276 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 042 | Batch: 200 | Loss: 0.01082 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 042 | Batch: 300 | Loss: 0.03136 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 042 | Batch: 400 | Loss: 0.01493 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 042 | Batch: 000 | Loss: 0.00743 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 042 | Batch: 100 | Loss: 0.03136 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 042 | Batch: 200 | Loss: 0.01478 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 042 | Batch: 300 | Loss: 0.02816 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 042 | Batch: 400 | Loss: 0.04530 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 042 | Batch: 000 | Loss: 0.01008 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 042 | Batch: 100 | Loss: 0.00617 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 042 | Batch: 200 | Loss: 0.03001 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 042 | Batch: 300 | Loss: 0.01705 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 042 | Batch: 400 | Loss: 0.00962 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 042 | Batch: 000 | Loss: 0.02099 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 042 | Batch: 100 | Loss: 0.02130 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 042 | Batch: 200 | Loss: 0.01263 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 042 | Batch: 300 | Loss: 0.02027 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 042 | Batch: 400 | Loss: 0.00983 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 042 | Batch: 000 | Loss: 0.03529 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 042 | Batch: 100 | Loss: 0.01525 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 042 | Batch: 200 | Loss: 0.00425 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 042 | Batch: 300 | Loss: 0.03115 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 042 | Batch: 400 | Loss: 0.00785 | Correct: 128/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 02:20:51,244 - INFO: Epoch: 042 | Validation Acc: 98.610 % | Historical Best: 98.690 %\n",
      "2022-09-25 02:20:51,244 - INFO: Epoch: 042 | Validation Acc: 98.610 % | Historical Best: 98.690 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 043 | Batch: 000 | Loss: 0.01210 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 043 | Batch: 100 | Loss: 0.02779 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 043 | Batch: 200 | Loss: 0.03243 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 043 | Batch: 300 | Loss: 0.03391 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 043 | Batch: 400 | Loss: 0.02841 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 043 | Batch: 000 | Loss: 0.02223 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 043 | Batch: 100 | Loss: 0.00259 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 043 | Batch: 200 | Loss: 0.00968 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 043 | Batch: 300 | Loss: 0.03494 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 043 | Batch: 400 | Loss: 0.02573 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 043 | Batch: 000 | Loss: 0.01110 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 043 | Batch: 100 | Loss: 0.01254 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 043 | Batch: 200 | Loss: 0.01933 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 043 | Batch: 300 | Loss: 0.03902 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 043 | Batch: 400 | Loss: 0.03317 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 043 | Batch: 000 | Loss: 0.02533 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 043 | Batch: 100 | Loss: 0.00464 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 043 | Batch: 200 | Loss: 0.00540 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 043 | Batch: 300 | Loss: 0.01297 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 043 | Batch: 400 | Loss: 0.03569 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 043 | Batch: 000 | Loss: 0.02631 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 043 | Batch: 100 | Loss: 0.01273 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 043 | Batch: 200 | Loss: 0.00867 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 043 | Batch: 300 | Loss: 0.00845 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 043 | Batch: 400 | Loss: 0.01599 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 043 | Batch: 000 | Loss: 0.01188 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 043 | Batch: 100 | Loss: 0.03204 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 043 | Batch: 200 | Loss: 0.01652 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 043 | Batch: 300 | Loss: 0.04335 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 043 | Batch: 400 | Loss: 0.01460 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 043 | Batch: 000 | Loss: 0.01421 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 043 | Batch: 100 | Loss: 0.03092 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 043 | Batch: 200 | Loss: 0.00775 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 043 | Batch: 300 | Loss: 0.03601 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 043 | Batch: 400 | Loss: 0.00780 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 043 | Batch: 000 | Loss: 0.01062 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 043 | Batch: 100 | Loss: 0.01924 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 043 | Batch: 200 | Loss: 0.03706 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 043 | Batch: 300 | Loss: 0.01003 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 043 | Batch: 400 | Loss: 0.01489 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 043 | Batch: 000 | Loss: 0.00543 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 043 | Batch: 100 | Loss: 0.00612 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 043 | Batch: 200 | Loss: 0.00556 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 043 | Batch: 300 | Loss: 0.01858 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 043 | Batch: 400 | Loss: 0.01207 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 043 | Batch: 000 | Loss: 0.01451 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 043 | Batch: 100 | Loss: 0.00721 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 043 | Batch: 200 | Loss: 0.00973 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 043 | Batch: 300 | Loss: 0.02733 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 043 | Batch: 400 | Loss: 0.00346 | Correct: 128/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 02:22:29,739 - INFO: Epoch: 043 | Validation Acc: 98.620 % | Historical Best: 98.690 %\n",
      "2022-09-25 02:22:29,739 - INFO: Epoch: 043 | Validation Acc: 98.620 % | Historical Best: 98.690 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 044 | Batch: 000 | Loss: 0.02836 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 044 | Batch: 100 | Loss: 0.01256 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 044 | Batch: 200 | Loss: 0.02154 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 044 | Batch: 300 | Loss: 0.02257 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 044 | Batch: 400 | Loss: 0.03482 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 044 | Batch: 000 | Loss: 0.00907 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 044 | Batch: 100 | Loss: 0.00913 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 044 | Batch: 200 | Loss: 0.01683 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 044 | Batch: 300 | Loss: 0.00425 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 044 | Batch: 400 | Loss: 0.03959 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 044 | Batch: 000 | Loss: 0.04590 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 044 | Batch: 100 | Loss: 0.03669 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 044 | Batch: 200 | Loss: 0.02718 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 044 | Batch: 300 | Loss: 0.05269 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 044 | Batch: 400 | Loss: 0.02634 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 044 | Batch: 000 | Loss: 0.00838 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 044 | Batch: 100 | Loss: 0.01797 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 044 | Batch: 200 | Loss: 0.01015 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 044 | Batch: 300 | Loss: 0.01055 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 044 | Batch: 400 | Loss: 0.01651 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 044 | Batch: 000 | Loss: 0.01567 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 044 | Batch: 100 | Loss: 0.01118 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 044 | Batch: 200 | Loss: 0.03406 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 044 | Batch: 300 | Loss: 0.00738 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 044 | Batch: 400 | Loss: 0.04189 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 044 | Batch: 000 | Loss: 0.02467 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 044 | Batch: 100 | Loss: 0.01694 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 044 | Batch: 200 | Loss: 0.01713 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 044 | Batch: 300 | Loss: 0.01771 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 044 | Batch: 400 | Loss: 0.02318 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 044 | Batch: 000 | Loss: 0.01068 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 044 | Batch: 100 | Loss: 0.03534 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 044 | Batch: 200 | Loss: 0.02466 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 044 | Batch: 300 | Loss: 0.04270 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 044 | Batch: 400 | Loss: 0.04141 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 044 | Batch: 000 | Loss: 0.02646 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 044 | Batch: 100 | Loss: 0.00478 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 044 | Batch: 200 | Loss: 0.01875 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 044 | Batch: 300 | Loss: 0.01182 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 044 | Batch: 400 | Loss: 0.01212 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 044 | Batch: 000 | Loss: 0.01130 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 044 | Batch: 100 | Loss: 0.01299 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 044 | Batch: 200 | Loss: 0.03510 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 044 | Batch: 300 | Loss: 0.02906 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 044 | Batch: 400 | Loss: 0.01509 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 044 | Batch: 000 | Loss: 0.00754 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 044 | Batch: 100 | Loss: 0.01837 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 044 | Batch: 200 | Loss: 0.01633 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 044 | Batch: 300 | Loss: 0.01203 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 044 | Batch: 400 | Loss: 0.01154 | Correct: 128/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 02:24:08,437 - INFO: Epoch: 044 | Validation Acc: 98.620 % | Historical Best: 98.690 %\n",
      "2022-09-25 02:24:08,437 - INFO: Epoch: 044 | Validation Acc: 98.620 % | Historical Best: 98.690 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 045 | Batch: 000 | Loss: 0.02383 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 045 | Batch: 100 | Loss: 0.00573 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 045 | Batch: 200 | Loss: 0.00760 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 045 | Batch: 300 | Loss: 0.02172 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 045 | Batch: 400 | Loss: 0.03607 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 045 | Batch: 000 | Loss: 0.02539 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 045 | Batch: 100 | Loss: 0.02708 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 045 | Batch: 200 | Loss: 0.02890 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 045 | Batch: 300 | Loss: 0.03149 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 045 | Batch: 400 | Loss: 0.02103 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 045 | Batch: 000 | Loss: 0.01852 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 045 | Batch: 100 | Loss: 0.00399 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 045 | Batch: 200 | Loss: 0.02013 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 045 | Batch: 300 | Loss: 0.04601 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 045 | Batch: 400 | Loss: 0.01769 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 045 | Batch: 000 | Loss: 0.02894 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 045 | Batch: 100 | Loss: 0.02047 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 045 | Batch: 200 | Loss: 0.02061 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 045 | Batch: 300 | Loss: 0.01529 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 045 | Batch: 400 | Loss: 0.02711 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 045 | Batch: 000 | Loss: 0.01236 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 045 | Batch: 100 | Loss: 0.01420 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 045 | Batch: 200 | Loss: 0.00914 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 045 | Batch: 300 | Loss: 0.02218 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 045 | Batch: 400 | Loss: 0.00887 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 045 | Batch: 000 | Loss: 0.01010 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 045 | Batch: 100 | Loss: 0.01534 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 045 | Batch: 200 | Loss: 0.01247 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 045 | Batch: 300 | Loss: 0.00190 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 045 | Batch: 400 | Loss: 0.00665 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 045 | Batch: 000 | Loss: 0.00644 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 045 | Batch: 100 | Loss: 0.01152 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 045 | Batch: 200 | Loss: 0.01783 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 045 | Batch: 300 | Loss: 0.01627 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 045 | Batch: 400 | Loss: 0.01694 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 045 | Batch: 000 | Loss: 0.02544 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 045 | Batch: 100 | Loss: 0.02362 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 045 | Batch: 200 | Loss: 0.04737 | Correct: 125/128\n",
      "Estimator: 007 | Epoch: 045 | Batch: 300 | Loss: 0.01481 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 045 | Batch: 400 | Loss: 0.05212 | Correct: 125/128\n",
      "Estimator: 008 | Epoch: 045 | Batch: 000 | Loss: 0.01786 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 045 | Batch: 100 | Loss: 0.01066 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 045 | Batch: 200 | Loss: 0.01544 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 045 | Batch: 300 | Loss: 0.02524 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 045 | Batch: 400 | Loss: 0.02559 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 045 | Batch: 000 | Loss: 0.01515 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 045 | Batch: 100 | Loss: 0.02953 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 045 | Batch: 200 | Loss: 0.05672 | Correct: 125/128\n",
      "Estimator: 009 | Epoch: 045 | Batch: 300 | Loss: 0.01705 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 045 | Batch: 400 | Loss: 0.04763 | Correct: 125/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 02:25:46,708 - INFO: Epoch: 045 | Validation Acc: 98.620 % | Historical Best: 98.690 %\n",
      "2022-09-25 02:25:46,708 - INFO: Epoch: 045 | Validation Acc: 98.620 % | Historical Best: 98.690 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 046 | Batch: 000 | Loss: 0.03252 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 046 | Batch: 100 | Loss: 0.03917 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 046 | Batch: 200 | Loss: 0.00999 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 046 | Batch: 300 | Loss: 0.04137 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 046 | Batch: 400 | Loss: 0.07897 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 046 | Batch: 000 | Loss: 0.01401 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 046 | Batch: 100 | Loss: 0.02016 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 046 | Batch: 200 | Loss: 0.02169 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 046 | Batch: 300 | Loss: 0.02764 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 046 | Batch: 400 | Loss: 0.02809 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 046 | Batch: 000 | Loss: 0.00952 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 046 | Batch: 100 | Loss: 0.01590 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 046 | Batch: 200 | Loss: 0.01753 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 046 | Batch: 300 | Loss: 0.02841 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 046 | Batch: 400 | Loss: 0.01126 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 046 | Batch: 000 | Loss: 0.06860 | Correct: 125/128\n",
      "Estimator: 003 | Epoch: 046 | Batch: 100 | Loss: 0.00688 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 046 | Batch: 200 | Loss: 0.04449 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 046 | Batch: 300 | Loss: 0.04687 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 046 | Batch: 400 | Loss: 0.02757 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 046 | Batch: 000 | Loss: 0.03731 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 046 | Batch: 100 | Loss: 0.06885 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 046 | Batch: 200 | Loss: 0.01823 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 046 | Batch: 300 | Loss: 0.05341 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 046 | Batch: 400 | Loss: 0.00468 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 046 | Batch: 000 | Loss: 0.01311 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 046 | Batch: 100 | Loss: 0.01673 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 046 | Batch: 200 | Loss: 0.04211 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 046 | Batch: 300 | Loss: 0.00585 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 046 | Batch: 400 | Loss: 0.00926 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 046 | Batch: 000 | Loss: 0.04214 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 046 | Batch: 100 | Loss: 0.01894 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 046 | Batch: 200 | Loss: 0.01664 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 046 | Batch: 300 | Loss: 0.01899 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 046 | Batch: 400 | Loss: 0.02265 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 046 | Batch: 000 | Loss: 0.00470 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 046 | Batch: 100 | Loss: 0.02422 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 046 | Batch: 200 | Loss: 0.00863 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 046 | Batch: 300 | Loss: 0.01710 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 046 | Batch: 400 | Loss: 0.02983 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 046 | Batch: 000 | Loss: 0.00731 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 046 | Batch: 100 | Loss: 0.01899 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 046 | Batch: 200 | Loss: 0.01920 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 046 | Batch: 300 | Loss: 0.02508 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 046 | Batch: 400 | Loss: 0.01875 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 046 | Batch: 000 | Loss: 0.03869 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 046 | Batch: 100 | Loss: 0.01747 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 046 | Batch: 200 | Loss: 0.02427 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 046 | Batch: 300 | Loss: 0.01056 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 046 | Batch: 400 | Loss: 0.01944 | Correct: 127/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 02:27:25,977 - INFO: Epoch: 046 | Validation Acc: 98.640 % | Historical Best: 98.690 %\n",
      "2022-09-25 02:27:25,977 - INFO: Epoch: 046 | Validation Acc: 98.640 % | Historical Best: 98.690 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 047 | Batch: 000 | Loss: 0.03946 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 047 | Batch: 100 | Loss: 0.01831 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 047 | Batch: 200 | Loss: 0.03923 | Correct: 126/128\n",
      "Estimator: 000 | Epoch: 047 | Batch: 300 | Loss: 0.00918 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 047 | Batch: 400 | Loss: 0.00631 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 047 | Batch: 000 | Loss: 0.01505 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 047 | Batch: 100 | Loss: 0.01071 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 047 | Batch: 200 | Loss: 0.01248 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 047 | Batch: 300 | Loss: 0.04153 | Correct: 125/128\n",
      "Estimator: 001 | Epoch: 047 | Batch: 400 | Loss: 0.02414 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 047 | Batch: 000 | Loss: 0.00809 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 047 | Batch: 100 | Loss: 0.00859 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 047 | Batch: 200 | Loss: 0.02080 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 047 | Batch: 300 | Loss: 0.03331 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 047 | Batch: 400 | Loss: 0.00650 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 047 | Batch: 000 | Loss: 0.02047 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 047 | Batch: 100 | Loss: 0.03425 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 047 | Batch: 200 | Loss: 0.00613 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 047 | Batch: 300 | Loss: 0.00518 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 047 | Batch: 400 | Loss: 0.02104 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 047 | Batch: 000 | Loss: 0.00746 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 047 | Batch: 100 | Loss: 0.01488 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 047 | Batch: 200 | Loss: 0.00986 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 047 | Batch: 300 | Loss: 0.04557 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 047 | Batch: 400 | Loss: 0.00930 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 047 | Batch: 000 | Loss: 0.01275 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 047 | Batch: 100 | Loss: 0.02658 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 047 | Batch: 200 | Loss: 0.01338 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 047 | Batch: 300 | Loss: 0.02680 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 047 | Batch: 400 | Loss: 0.01230 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 047 | Batch: 000 | Loss: 0.01595 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 047 | Batch: 100 | Loss: 0.00520 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 047 | Batch: 200 | Loss: 0.01579 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 047 | Batch: 300 | Loss: 0.00869 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 047 | Batch: 400 | Loss: 0.01039 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 047 | Batch: 000 | Loss: 0.01434 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 047 | Batch: 100 | Loss: 0.02512 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 047 | Batch: 200 | Loss: 0.05745 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 047 | Batch: 300 | Loss: 0.03061 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 047 | Batch: 400 | Loss: 0.01473 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 047 | Batch: 000 | Loss: 0.02024 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 047 | Batch: 100 | Loss: 0.03334 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 047 | Batch: 200 | Loss: 0.00868 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 047 | Batch: 300 | Loss: 0.00531 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 047 | Batch: 400 | Loss: 0.01599 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 047 | Batch: 000 | Loss: 0.02483 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 047 | Batch: 100 | Loss: 0.00700 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 047 | Batch: 200 | Loss: 0.04384 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 047 | Batch: 300 | Loss: 0.01752 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 047 | Batch: 400 | Loss: 0.02692 | Correct: 127/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 02:29:04,777 - INFO: Epoch: 047 | Validation Acc: 98.550 % | Historical Best: 98.690 %\n",
      "2022-09-25 02:29:04,777 - INFO: Epoch: 047 | Validation Acc: 98.550 % | Historical Best: 98.690 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 048 | Batch: 000 | Loss: 0.01453 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 048 | Batch: 100 | Loss: 0.00738 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 048 | Batch: 200 | Loss: 0.03578 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 048 | Batch: 300 | Loss: 0.02825 | Correct: 125/128\n",
      "Estimator: 000 | Epoch: 048 | Batch: 400 | Loss: 0.01787 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 048 | Batch: 000 | Loss: 0.00529 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 048 | Batch: 100 | Loss: 0.02076 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 048 | Batch: 200 | Loss: 0.02434 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 048 | Batch: 300 | Loss: 0.00684 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 048 | Batch: 400 | Loss: 0.03910 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 048 | Batch: 000 | Loss: 0.02397 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 048 | Batch: 100 | Loss: 0.03214 | Correct: 125/128\n",
      "Estimator: 002 | Epoch: 048 | Batch: 200 | Loss: 0.01062 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 048 | Batch: 300 | Loss: 0.01396 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 048 | Batch: 400 | Loss: 0.00901 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 048 | Batch: 000 | Loss: 0.00602 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 048 | Batch: 100 | Loss: 0.01585 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 048 | Batch: 200 | Loss: 0.01049 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 048 | Batch: 300 | Loss: 0.03588 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 048 | Batch: 400 | Loss: 0.00463 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 048 | Batch: 000 | Loss: 0.03282 | Correct: 126/128\n",
      "Estimator: 004 | Epoch: 048 | Batch: 100 | Loss: 0.01143 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 048 | Batch: 200 | Loss: 0.05745 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 048 | Batch: 300 | Loss: 0.04646 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 048 | Batch: 400 | Loss: 0.00313 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 048 | Batch: 000 | Loss: 0.02085 | Correct: 126/128\n",
      "Estimator: 005 | Epoch: 048 | Batch: 100 | Loss: 0.00422 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 048 | Batch: 200 | Loss: 0.00996 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 048 | Batch: 300 | Loss: 0.04021 | Correct: 125/128\n",
      "Estimator: 005 | Epoch: 048 | Batch: 400 | Loss: 0.01353 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 048 | Batch: 000 | Loss: 0.03356 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 048 | Batch: 100 | Loss: 0.00604 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 048 | Batch: 200 | Loss: 0.04703 | Correct: 125/128\n",
      "Estimator: 006 | Epoch: 048 | Batch: 300 | Loss: 0.00531 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 048 | Batch: 400 | Loss: 0.01027 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 048 | Batch: 000 | Loss: 0.03536 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 048 | Batch: 100 | Loss: 0.00964 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 048 | Batch: 200 | Loss: 0.00824 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 048 | Batch: 300 | Loss: 0.01141 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 048 | Batch: 400 | Loss: 0.05182 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 048 | Batch: 000 | Loss: 0.01945 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 048 | Batch: 100 | Loss: 0.01504 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 048 | Batch: 200 | Loss: 0.01254 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 048 | Batch: 300 | Loss: 0.02475 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 048 | Batch: 400 | Loss: 0.00305 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 048 | Batch: 000 | Loss: 0.01214 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 048 | Batch: 100 | Loss: 0.03443 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 048 | Batch: 200 | Loss: 0.00989 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 048 | Batch: 300 | Loss: 0.04531 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 048 | Batch: 400 | Loss: 0.03052 | Correct: 127/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 02:30:43,227 - INFO: Epoch: 048 | Validation Acc: 98.610 % | Historical Best: 98.690 %\n",
      "2022-09-25 02:30:43,227 - INFO: Epoch: 048 | Validation Acc: 98.610 % | Historical Best: 98.690 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator: 000 | Epoch: 049 | Batch: 000 | Loss: 0.01982 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 049 | Batch: 100 | Loss: 0.00622 | Correct: 128/128\n",
      "Estimator: 000 | Epoch: 049 | Batch: 200 | Loss: 0.01307 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 049 | Batch: 300 | Loss: 0.02377 | Correct: 127/128\n",
      "Estimator: 000 | Epoch: 049 | Batch: 400 | Loss: 0.06713 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 049 | Batch: 000 | Loss: 0.02617 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 049 | Batch: 100 | Loss: 0.02378 | Correct: 127/128\n",
      "Estimator: 001 | Epoch: 049 | Batch: 200 | Loss: 0.02166 | Correct: 126/128\n",
      "Estimator: 001 | Epoch: 049 | Batch: 300 | Loss: 0.01414 | Correct: 128/128\n",
      "Estimator: 001 | Epoch: 049 | Batch: 400 | Loss: 0.01107 | Correct: 127/128\n",
      "Estimator: 002 | Epoch: 049 | Batch: 000 | Loss: 0.03363 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 049 | Batch: 100 | Loss: 0.05902 | Correct: 124/128\n",
      "Estimator: 002 | Epoch: 049 | Batch: 200 | Loss: 0.00537 | Correct: 128/128\n",
      "Estimator: 002 | Epoch: 049 | Batch: 300 | Loss: 0.03680 | Correct: 126/128\n",
      "Estimator: 002 | Epoch: 049 | Batch: 400 | Loss: 0.01438 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 049 | Batch: 000 | Loss: 0.04539 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 049 | Batch: 100 | Loss: 0.01005 | Correct: 128/128\n",
      "Estimator: 003 | Epoch: 049 | Batch: 200 | Loss: 0.01593 | Correct: 127/128\n",
      "Estimator: 003 | Epoch: 049 | Batch: 300 | Loss: 0.02761 | Correct: 126/128\n",
      "Estimator: 003 | Epoch: 049 | Batch: 400 | Loss: 0.11987 | Correct: 122/128\n",
      "Estimator: 004 | Epoch: 049 | Batch: 000 | Loss: 0.01156 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 049 | Batch: 100 | Loss: 0.08261 | Correct: 125/128\n",
      "Estimator: 004 | Epoch: 049 | Batch: 200 | Loss: 0.01331 | Correct: 128/128\n",
      "Estimator: 004 | Epoch: 049 | Batch: 300 | Loss: 0.03824 | Correct: 127/128\n",
      "Estimator: 004 | Epoch: 049 | Batch: 400 | Loss: 0.01337 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 049 | Batch: 000 | Loss: 0.02335 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 049 | Batch: 100 | Loss: 0.00596 | Correct: 128/128\n",
      "Estimator: 005 | Epoch: 049 | Batch: 200 | Loss: 0.01504 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 049 | Batch: 300 | Loss: 0.01688 | Correct: 127/128\n",
      "Estimator: 005 | Epoch: 049 | Batch: 400 | Loss: 0.02236 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 049 | Batch: 000 | Loss: 0.01888 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 049 | Batch: 100 | Loss: 0.00546 | Correct: 128/128\n",
      "Estimator: 006 | Epoch: 049 | Batch: 200 | Loss: 0.01899 | Correct: 127/128\n",
      "Estimator: 006 | Epoch: 049 | Batch: 300 | Loss: 0.02706 | Correct: 126/128\n",
      "Estimator: 006 | Epoch: 049 | Batch: 400 | Loss: 0.01505 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 049 | Batch: 000 | Loss: 0.03393 | Correct: 126/128\n",
      "Estimator: 007 | Epoch: 049 | Batch: 100 | Loss: 0.01127 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 049 | Batch: 200 | Loss: 0.00359 | Correct: 128/128\n",
      "Estimator: 007 | Epoch: 049 | Batch: 300 | Loss: 0.02017 | Correct: 127/128\n",
      "Estimator: 007 | Epoch: 049 | Batch: 400 | Loss: 0.01591 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 049 | Batch: 000 | Loss: 0.00352 | Correct: 128/128\n",
      "Estimator: 008 | Epoch: 049 | Batch: 100 | Loss: 0.01157 | Correct: 127/128\n",
      "Estimator: 008 | Epoch: 049 | Batch: 200 | Loss: 0.04251 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 049 | Batch: 300 | Loss: 0.03138 | Correct: 126/128\n",
      "Estimator: 008 | Epoch: 049 | Batch: 400 | Loss: 0.03647 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 049 | Batch: 000 | Loss: 0.02407 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 049 | Batch: 100 | Loss: 0.01765 | Correct: 128/128\n",
      "Estimator: 009 | Epoch: 049 | Batch: 200 | Loss: 0.02882 | Correct: 127/128\n",
      "Estimator: 009 | Epoch: 049 | Batch: 300 | Loss: 0.02122 | Correct: 126/128\n",
      "Estimator: 009 | Epoch: 049 | Batch: 400 | Loss: 0.01483 | Correct: 127/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 02:32:22,267 - INFO: Epoch: 049 | Validation Acc: 98.540 % | Historical Best: 98.690 %\n",
      "2022-09-25 02:32:22,267 - INFO: Epoch: 049 | Validation Acc: 98.540 % | Historical Best: 98.690 %\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_loader,\n",
    "    epochs=50,\n",
    "    test_loader=test_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b59955",
   "metadata": {},
   "source": [
    "# Own prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a0033f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab33543",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
